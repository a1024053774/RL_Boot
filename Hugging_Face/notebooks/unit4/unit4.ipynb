{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjRWziAVU2lZ"
   },
   "source": [
    "# ç¬¬ 4 å•å…ƒï¼šä½¿ç”¨ PyTorch ç¼–å†™ä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼šReinforceï¼Œå¹¶æµ‹è¯•å…¶é²æ£’æ€§ ğŸ’ª\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit6/thumbnail.png\" alt=\"thumbnail\"/>\n",
    "\n",
    "\n",
    "åœ¨æœ¬ Notebook ä¸­ï¼Œä½ å°†ä»å¤´å¼€å§‹ç¼–å†™ä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼šReinforce (ä¹Ÿç§°ä¸ºè’™ç‰¹å¡æ´›ç­–ç•¥æ¢¯åº¦)ã€‚\n",
    "\n",
    "Reinforce æ˜¯ä¸€ç§*åŸºäºç­–ç•¥çš„æ–¹æ³•*ï¼šä¸€ç§**ç›´æ¥å°è¯•ä¼˜åŒ–ç­–ç•¥è€Œä¸ä½¿ç”¨åŠ¨ä½œä»·å€¼å‡½æ•°**çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚\n",
    "\n",
    "æ›´å‡†ç¡®åœ°è¯´ï¼ŒReinforce æ˜¯ä¸€ç§*ç­–ç•¥æ¢¯åº¦æ–¹æ³•*ï¼Œå®ƒæ˜¯*åŸºäºç­–ç•¥çš„æ–¹æ³•*çš„ä¸€ä¸ªå­ç±»ï¼Œæ—¨åœ¨ä½¿ç”¨**æ¢¯åº¦ä¸Šå‡æ³•ä¼°è®¡æœ€ä¼˜ç­–ç•¥çš„æƒé‡æ¥ç›´æ¥ä¼˜åŒ–ç­–ç•¥**ã€‚\n",
    "\n",
    "ä¸ºäº†æµ‹è¯•å…¶é²æ£’æ€§ï¼Œæˆ‘ä»¬å°†åœ¨ 2 ä¸ªä¸åŒçš„ç®€å•ç¯å¢ƒä¸­è®­ç»ƒå®ƒï¼š\n",
    "- Cartpole-v1\n",
    "- PixelcopterEnv\n",
    "\n",
    "â¬‡ï¸ è¿™æ˜¯**ä½ å°†åœ¨æœ¬ Notebook ç»“æŸæ—¶å®ç°**çš„æ•ˆæœç¤ºä¾‹ã€‚â¬‡ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "  <img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit6/envs.gif\" alt=\"Environments\"/>\n"
   ],
   "metadata": {
    "id": "s4rBom2sbo7S"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ğŸ® ç¯å¢ƒ:\n",
    "\n",
    "- [CartPole-v1](https://www.gymlibrary.dev/environments/classic_control/cart_pole/)\n",
    "- [PixelCopter](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pixelcopter.html)\n",
    "\n",
    "### ğŸ“š RL åº“:\n",
    "\n",
    "- Python\n",
    "- PyTorch\n",
    "\n",
    "\n",
    "æˆ‘ä»¬ä¸€ç›´åœ¨åŠªåŠ›æ”¹è¿›æˆ‘ä»¬çš„æ•™ç¨‹ï¼Œå› æ­¤**å¦‚æœä½ åœ¨æœ¬ Notebook ä¸­å‘ç°ä»»ä½•é—®é¢˜**ï¼Œè¯·åœ¨[GitHub ä»“åº“ä¸­æå‡ºé—®é¢˜](https://github.com/huggingface/deep-rl-class/issues)ã€‚"
   ],
   "metadata": {
    "id": "BPLwsPajb1f8"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_WSo0VUV99t"
   },
   "source": [
    "## æœ¬ Notebook çš„ç›®æ ‡ ğŸ†\n",
    "åœ¨æœ¬ Notebook ç»“æŸæ—¶ï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "- **ä½¿ç”¨ PyTorch ä»é›¶å¼€å§‹ç¼–å†™ Reinforce ç®—æ³•ã€‚**\n",
    "- **ä½¿ç”¨ç®€å•çš„ç¯å¢ƒæµ‹è¯•ä½ çš„æ™ºèƒ½ä½“çš„é²æ£’æ€§ã€‚**\n",
    "- **å°†ä½ è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“æ¨é€åˆ° Hub**ï¼Œå¹¶é™„ä¸Šç²¾å½©çš„å›æ”¾è§†é¢‘å’Œè¯„ä¼°åˆ†æ•° ğŸ”¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEPrZg2eWa4R"
   },
   "source": [
    "## æœ¬ Notebook æ¥è‡ªæ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p5HnEefISCB"
   },
   "source": [
    "åœ¨è¿™ä¸ªå…è´¹è¯¾ç¨‹ä¸­ï¼Œä½ å°†ï¼š\n",
    "\n",
    "- ğŸ“– **åœ¨ç†è®ºå’Œå®è·µä¸­**å­¦ä¹ æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚\n",
    "- ğŸ§‘â€ğŸ’» å­¦ä¹ **ä½¿ç”¨è‘—åçš„æ·±åº¦ RL åº“**ï¼Œå¦‚ Stable Baselines3ã€RL Baselines3 Zooã€CleanRL å’Œ Sample Factory 2.0ã€‚\n",
    "- ğŸ¤– åœ¨**ç‹¬ç‰¹çš„ç¯å¢ƒä¸­è®­ç»ƒæ™ºèƒ½ä½“**\n",
    "\n",
    "æ›´å¤šå†…å®¹è¯·æŸ¥çœ‹ ğŸ“š è¯¾ç¨‹å¤§çº² ğŸ‘‰ https://simoninithomas.github.io/deep-rl-course\n",
    "\n",
    "åˆ«å¿˜äº†**<a href=\"http://eepurl.com/ic5ZUD\">æ³¨å†Œè¯¾ç¨‹</a>** (æˆ‘ä»¬æ”¶é›†ä½ çš„ç”µå­é‚®ä»¶æ˜¯ä¸ºäº†**åœ¨æ¯ä¸ªå•å…ƒå‘å¸ƒæ—¶å‘ä½ å‘é€é“¾æ¥ï¼Œå¹¶ä¸ºä½ æä¾›æœ‰å…³æŒ‘æˆ˜å’Œæ›´æ–°çš„ä¿¡æ¯**)ã€‚\n",
    "\n",
    "\n",
    "ä¿æŒè”ç³»çš„æœ€ä½³æ–¹å¼æ˜¯åŠ å…¥æˆ‘ä»¬çš„ Discord æœåŠ¡å™¨ï¼Œä¸ç¤¾åŒºå’Œæˆ‘ä»¬äº¤æµ ğŸ‘‰ğŸ» https://discord.gg/ydHrjt3WP5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjY-eq3eWh9O"
   },
   "source": [
    "## å…ˆå†³æ¡ä»¶ ğŸ—ï¸\n",
    "åœ¨æ·±å…¥å­¦ä¹ æœ¬ Notebook ä¹‹å‰ï¼Œä½ éœ€è¦ï¼š\n",
    "\n",
    "ğŸ”² ğŸ“š [é€šè¿‡é˜…è¯»ç¬¬ 4 å•å…ƒæ¥å­¦ä¹ ç­–ç•¥æ¢¯åº¦](https://huggingface.co/deep-rl-course/unit4/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# è®©æˆ‘ä»¬ä»å¤´å¼€å§‹ç¼–å†™ Reinforce ç®—æ³• ğŸ”¥\n",
    "\n",
    "\n",
    "è¦é€šè¿‡è®¤è¯æµç¨‹éªŒè¯æ­¤å®è·µé¡¹ç›®ï¼Œä½ éœ€è¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ¨é€åˆ° Hubã€‚\n",
    "\n",
    "- `Cartpole-v1` çš„ç»“æœéœ€ >= 350ã€‚\n",
    "- `PixelCopter` çš„ç»“æœéœ€ >= 5ã€‚\n",
    "\n",
    "è¦æ‰¾åˆ°ä½ çš„ç»“æœï¼Œè¯·è½¬åˆ°æ’è¡Œæ¦œå¹¶æ‰¾åˆ°ä½ çš„æ¨¡å‹ï¼Œ**ç»“æœ = mean_reward - std of reward**ã€‚**å¦‚æœä½ åœ¨æ’è¡Œæ¦œä¸Šçœ‹ä¸åˆ°ä½ çš„æ¨¡å‹ï¼Œè¯·è½¬åˆ°æ’è¡Œæ¦œé¡µé¢åº•éƒ¨ï¼Œç„¶åå•å‡»åˆ·æ–°æŒ‰é’®**ã€‚\n",
    "\n",
    "æœ‰å…³è®¤è¯æµç¨‹çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ­¤éƒ¨åˆ† ğŸ‘‰ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process\n"
   ],
   "metadata": {
    "id": "Bsh4ZAamchSl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## æ£€æŸ¥ GPU æ”¯æŒ ğŸ’ª\n",
    "ä¸ºäº†**åŠ é€Ÿæ™ºèƒ½ä½“çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ GPU**ã€‚ä¸‹é¢çš„ä»£ç å°†æ£€æŸ¥ PyTorch æ˜¯å¦å¯ä»¥è®¿é—® CUDA enabled çš„ GPUã€‚\n",
    "å¦‚æœä½ çš„è®¡ç®—æœºä¸Šæœ‰æ­£ç¡®é…ç½®çš„ NVIDIA GPUï¼Œä½ åº”è¯¥ä¼šçœ‹åˆ° `device:cuda:0`ã€‚"
   ],
   "metadata": {
    "id": "PU4FVzaoM6fC"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kaJu5FeZxXGY",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:31:30.819257Z",
     "start_time": "2025-08-12T18:31:30.815255Z"
    }
   },
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "## åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿæ˜¾ç¤ºå™¨ ğŸ–¥\n",
    "\n",
    "åœ¨æœ¬åœ°è¿è¡Œæ—¶ï¼Œå¦‚æœä½ æœ‰æ¡Œé¢ç¯å¢ƒï¼Œé€šå¸¸ä¸éœ€è¦è¿™ä¸€æ­¥ã€‚ä½†æ˜¯ï¼Œå¦‚æœä½ åœ¨æ²¡æœ‰æ˜¾ç¤ºå™¨çš„æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œæˆ–è€…ä¸ºäº†ç¡®ä¿ä»£ç çš„å¯ç§»æ¤æ€§ï¼Œåˆ›å»ºä¸€ä¸ªè™šæ‹Ÿå±å¹•æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚\n",
    "ä¸‹é¢çš„å•å…ƒæ ¼å°†å®‰è£…æ‰€éœ€çš„åº“å¹¶å¯åŠ¨ä¸€ä¸ªè™šæ‹Ÿå±å¹•ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨åå°æ¸²æŸ“ç¯å¢ƒå¹¶å½•åˆ¶è§†é¢‘äº†ã€‚\n"
   ],
   "metadata": {
    "id": "bTpYcVZVMzUI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### åœ¨æœ¬åœ°å®‰è£…ä¾èµ–é¡¹\n",
    "è¦è¿è¡Œæ­¤ Notebookï¼Œä½ éœ€è¦å®‰è£…å‡ ä¸ª Python åŒ…ã€‚åœ¨ä½ çš„ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å®‰è£…å®ƒä»¬ã€‚\n",
    "\n",
    "å¯¹äºè§†é¢‘å½•åˆ¶åŠŸèƒ½ï¼Œä½ å¯èƒ½è¿˜éœ€è¦å®‰è£… `ffmpeg`ã€‚åœ¨ Ubuntu/Debian ä¸Šï¼Œä½ å¯ä»¥ä½¿ç”¨ `sudo apt install ffmpeg`ã€‚åœ¨ macOS ä¸Šï¼Œå¯ä»¥ä½¿ç”¨ `brew install ffmpeg`ã€‚\n",
    "\n",
    "```bash\n",
    "# å®‰è£… Python åŒ…\n",
    "pip install gym==0.21.0 gym-games==0.2.0 pygame==2.1.0 huggingface-hub==0.8.1 protobuf==3.19.5 imageio==2.9.0 pyvirtualdisplay\n",
    "```\n",
    "ä¸‹é¢çš„ä»£ç å•å…ƒæ ¼æ˜¯ä¸ºäº†åœ¨ Notebook ç¯å¢ƒä¸­è¿è¡Œè€Œä¿ç•™çš„ï¼Œä½†å»ºè®®åœ¨ç»ˆç«¯ä¸­è¿›è¡Œå®‰è£…ã€‚"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV6wjQ7Be7p5"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !apt install python-opengl # åœ¨æŸäº›ç³»ç»Ÿä¸Šå¯èƒ½éœ€è¦\n",
    "# !apt install ffmpeg\n",
    "# !apt install xvfb\n",
    "# !pip install pyvirtualdisplay\n",
    "# !pip install pyglet==1.5.1"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# è™šæ‹Ÿæ˜¾ç¤º\n",
    "# å¦‚æœä½ åœ¨æ²¡æœ‰æ˜¾ç¤ºå™¨çš„æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œæˆ–è€…åœ¨æœ¬åœ°é‡åˆ°æ¸²æŸ“é—®é¢˜ï¼Œè¯·å–æ¶ˆæ³¨é‡Šä»¥ä¸‹ä»£ç \n",
    "try:\n",
    "    from pyvirtualdisplay import Display\n",
    "    virtual_display = Display(visible=0, size=(1400, 900))\n",
    "    virtual_display.start()\n",
    "except ImportError:\n",
    "    print(\"PyVirtualDisplay æœªå®‰è£…ï¼Œå°†è·³è¿‡è™šæ‹Ÿæ˜¾ç¤ºè®¾ç½®ã€‚åœ¨æœ¬åœ°æ¡Œé¢ä¸Šé€šå¸¸ä¸éœ€è¦å®ƒã€‚\")\n"
   ],
   "metadata": {
    "id": "Sr-Nuyb1dBm0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjrLfPFIW8XK"
   },
   "source": [
    "## å®‰è£…ä¾èµ–é¡¹ ğŸ”½\n",
    "ç¬¬ä¸€æ­¥æ˜¯å®‰è£…ä¾èµ–é¡¹ã€‚æˆ‘ä»¬å°†å®‰è£…å¤šä¸ªåº“ï¼š\n",
    "\n",
    "- `gym`\n",
    "- `gym-games`: ä½¿ç”¨ PyGame åˆ¶ä½œçš„é¢å¤– gym ç¯å¢ƒã€‚\n",
    "- `huggingface_hub`: ğŸ¤— ä½œä¸ºä¸€ä¸ªä¸­å¿ƒæ¢çº½ï¼Œä»»ä½•äººéƒ½å¯ä»¥åœ¨è¿™é‡Œå…±äº«å’Œæ¢ç´¢æ¨¡å‹å’Œæ•°æ®é›†ã€‚å®ƒå…·æœ‰ç‰ˆæœ¬æ§åˆ¶ã€æŒ‡æ ‡ã€å¯è§†åŒ–ç­‰åŠŸèƒ½ï¼Œå¯è®©ä½ è½»æ¾ä¸ä»–äººåä½œã€‚\n",
    "\n",
    "ä½ å¯èƒ½æƒ³çŸ¥é“æˆ‘ä»¬ä¸ºä»€ä¹ˆå®‰è£… `gym` è€Œä¸æ˜¯ `gymnasium` (gym çš„ä¸€ä¸ªæ›´æ–°ç‰ˆæœ¬)ï¼Ÿ**å› ä¸ºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨çš„ `gym-games` å°šæœªæ›´æ–°ä»¥æ”¯æŒ `gymnasium`**ã€‚\n",
    "\n",
    "ä½ åœ¨è¿™é‡Œä¼šé‡åˆ°çš„åŒºåˆ«ï¼š\n",
    "- åœ¨ `gym` ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ `terminated` å’Œ `truncated`ï¼Œåªæœ‰ `done`ã€‚\n",
    "- åœ¨ `gym` ä¸­ï¼Œä½¿ç”¨ `env.step()` è¿”å› `state, reward, done, info`\n",
    "\n",
    "ä½ å¯ä»¥åœ¨è¿™é‡Œäº†è§£æ›´å¤šå…³äº Gym å’Œ Gymnasium ä¹‹é—´çš„åŒºåˆ« ğŸ‘‰ https://gymnasium.farama.org/content/migration-guide/\n",
    "\n",
    "\n",
    "ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°æ‰€æœ‰å¯ç”¨çš„ Reinforce æ¨¡å‹ ğŸ‘‰ https://huggingface.co/models?other=reinforce\n",
    "\n",
    "ä½ å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°æ‰€æœ‰æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ ğŸ‘‰ https://huggingface.co/models?pipeline_tag=reinforcement-learning\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# æˆ‘ä»¬ä» GitHub åŠ è½½ requirements.txt ä»¥ç¡®ä¿ç‰ˆæœ¬ä¸€è‡´\n",
    "# å»ºè®®åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨ 'pip install -r <url>' æˆ–ä¸‹è½½æ–‡ä»¶å 'pip install -r requirements-unit4.txt' æ¥å®‰è£…\n",
    "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt"
   ],
   "metadata": {
    "id": "e8ZVi-uydpgL",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:32:46.601444Z",
     "start_time": "2025-08-12T12:31:50.636814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ntasfi/PyGame-Learning-Environment.git (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 1))\n",
      "  Cloning https://github.com/ntasfi/PyGame-Learning-Environment.git to c:\\users\\10240\\appdata\\local\\temp\\pip-req-build-8_9wvlyi\n",
      "  Resolved https://github.com/ntasfi/PyGame-Learning-Environment.git to commit 3dbe79dc0c35559bb441b9359948aabf9bb3d331\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting git+https://github.com/simoninithomas/gym-games (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2))\n",
      "  Cloning https://github.com/simoninithomas/gym-games to c:\\users\\10240\\appdata\\local\\temp\\pip-req-build-m8_yi_s4\n",
      "  Resolved https://github.com/simoninithomas/gym-games to commit f31695e4ba028400628dc054ee8a436f28193f0b\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (0.29.1)\n",
      "Requirement already satisfied: imageio-ffmpeg in d:\\developmentsoftware\\anaconda\\envs\\py311\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 4)) (0.6.0)\n",
      "Collecting pyyaml==6.0 (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 5))\n",
      "  Using cached PyYAML-6.0-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in d:\\developmentsoftware\\anaconda\\envs\\py311\\lib\\site-packages (from ple==0.0.1->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from ple==0.0.1->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: gym>=0.13.0 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (0.26.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (75.8.2)\n",
      "Requirement already satisfied: pygame>=1.9.6 in d:\\developmentsoftware\\anaconda\\envs\\py311\\lib\\site-packages (from gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\developmentsoftware\\anaconda\\envs\\py311\\lib\\site-packages (from gym>=0.13.0->gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from gym>=0.13.0->gym-games==1.0.4->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 2)) (0.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10240\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit4/requirements-unit4.txt (line 3)) (2025.1.31)\n",
      "Using cached PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "Successfully installed pyyaml-6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/ntasfi/PyGame-Learning-Environment.git 'C:\\Users\\10240\\AppData\\Local\\Temp\\pip-req-build-8_9wvlyi'\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/simoninithomas/gym-games 'C:\\Users\\10240\\AppData\\Local\\Temp\\pip-req-build-m8_yi_s4'\n",
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\DevelopmentSoftware\\Anaconda\\envs\\py311\\Lib\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.19 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.0.1 which is incompatible.\n",
      "langchain-community 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.0.1 which is incompatible.\n",
      "langchain-core 0.3.40 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "rapidocr-onnxruntime 1.3.24 requires numpy<2.0.0,>=1.19.5, but you have numpy 2.0.1 which is incompatible.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAHAq6RZW3rn"
   },
   "source": [
    "## å¯¼å…¥åŒ… ğŸ“¦\n",
    "é™¤äº†å¯¼å…¥å·²å®‰è£…çš„åº“ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯¼å…¥ï¼š\n",
    "\n",
    "- `imageio`: ä¸€ä¸ªå¸®åŠ©æˆ‘ä»¬ç”Ÿæˆå›æ”¾è§†é¢‘çš„åº“\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V8oadoJSWp7C",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:31:35.524640Z",
     "start_time": "2025-08-12T18:31:35.515796Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Gym\n",
    "import gym\n",
    "import gym_pygame\n",
    "\n",
    "# Hugging Face Hub\n",
    "from huggingface_hub import notebook_login # ç™»å½•æˆ‘ä»¬çš„ Hugging Face å¸æˆ·ä»¥ä¸Šä¼ æ¨¡å‹åˆ° Hub\n",
    "import imageio"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBPecCtBL_pZ"
   },
   "source": [
    "æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½å®ç°æˆ‘ä»¬çš„ Reinforce ç®—æ³•äº† ğŸ”¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KEyKYo2ZSC-"
   },
   "source": [
    "# ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“ï¼šç© CartPole-v1 ğŸ¤–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haLArKURMyuF"
   },
   "source": [
    "## åˆ›å»º CartPole ç¯å¢ƒå¹¶äº†è§£å…¶å·¥ä½œåŸç†\n",
    "### [ç¯å¢ƒ ğŸ®](https://www.gymlibrary.dev/environments/classic_control/cart_pole/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH_TaLKFXo_8"
   },
   "source": [
    "### ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨åƒ CartPole-v1 è¿™æ ·çš„ç®€å•ç¯å¢ƒï¼Ÿ\n",
    "æ­£å¦‚[å¼ºåŒ–å­¦ä¹ æŠ€å·§å’Œçªé—¨](https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html)ä¸­æ‰€è§£é‡Šçš„ï¼Œå½“ä½ ä»å¤´å¼€å§‹å®ç°ä½ çš„æ™ºèƒ½ä½“æ—¶ï¼Œä½ éœ€è¦**åœ¨è¿›å…¥æ›´æ·±å±‚æ¬¡ä¹‹å‰ï¼Œç¡®ä¿å®ƒåœ¨ç®€å•çš„ç¯å¢ƒä¸­æ­£å¸¸å·¥ä½œå¹¶æ‰¾åˆ°é”™è¯¯**ã€‚å› ä¸ºåœ¨ç®€å•çš„ç¯å¢ƒä¸­æ‰¾åˆ°é”™è¯¯ä¼šå®¹æ˜“å¾—å¤šã€‚\n",
    "\n",
    "\n",
    "> å°è¯•åœ¨ç©å…·é—®é¢˜ä¸Šè·å¾—ä¸€äº›â€œç”Ÿå‘½è¿¹è±¡â€\n",
    "\n",
    "\n",
    "> é€šè¿‡åœ¨è¶Šæ¥è¶Šéš¾çš„ç¯å¢ƒä¸­è¿è¡Œæ¥éªŒè¯å®ç°ï¼ˆä½ å¯ä»¥å°†ç»“æœä¸ RL zoo è¿›è¡Œæ¯”è¾ƒï¼‰ã€‚ä½ é€šå¸¸éœ€è¦ä¸ºæ­¤æ­¥éª¤è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–ã€‚\n",
    "___\n",
    "### CartPole-v1 ç¯å¢ƒ\n",
    "\n",
    "> ä¸€æ ¹æ†é€šè¿‡ä¸€ä¸ªæ— é©±åŠ¨çš„å…³èŠ‚è¿æ¥åˆ°ä¸€ä¸ªåœ¨æ— æ‘©æ“¦è½¨é“ä¸Šç§»åŠ¨çš„æ¨è½¦ä¸Šã€‚æ‘†é”¤å‚ç›´æ”¾ç½®åœ¨æ¨è½¦ä¸Šï¼Œç›®æ ‡æ˜¯é€šè¿‡å‘æ¨è½¦æ–½åŠ å‘å·¦å’Œå‘å³çš„åŠ›æ¥å¹³è¡¡æ†ã€‚\n",
    "\n",
    "\n",
    "\n",
    "æ‰€ä»¥ï¼Œæˆ‘ä»¬ä» CartPole-v1 å¼€å§‹ã€‚ç›®æ ‡æ˜¯å‘å·¦æˆ–å‘å³æ¨åŠ¨æ¨è½¦ï¼Œ**ä»¥ä¾¿æ†ä¿æŒå¹³è¡¡ã€‚**\n",
    "\n",
    "å¦‚æœå‡ºç°ä»¥ä¸‹æƒ…å†µï¼Œå›åˆç»“æŸï¼š\n",
    "- æ†çš„è§’åº¦å¤§äº Â±12Â°\n",
    "- æ¨è½¦ä½ç½®å¤§äº Â±2.4\n",
    "- å›åˆé•¿åº¦å¤§äº 500\n",
    "\n",
    "æ¯å½“æ†ä¿æŒå¹³è¡¡ï¼Œæˆ‘ä»¬æ¯ä¸ªæ—¶é—´æ­¥éƒ½ä¼šè·å¾— +1 çš„å¥–åŠ± ğŸ’°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "POOOk15_K6KA",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:31:39.894378Z",
     "start_time": "2025-08-12T18:31:39.888666Z"
    }
   },
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "# åˆ›å»ºç¯å¢ƒ\n",
    "env = gym.make(env_id)\n",
    "\n",
    "# åˆ›å»ºè¯„ä¼°ç¯å¢ƒ\n",
    "eval_env = gym.make(env_id)\n",
    "\n",
    "# è·å–çŠ¶æ€ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´\n",
    "s_size = env.observation_space.shape[0]\n",
    "a_size = env.action_space.n"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FMLFrjiBNLYJ",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:31:46.861570Z",
     "start_time": "2025-08-12T18:31:46.855363Z"
    }
   },
   "source": [
    "print(\"_____è§‚å¯Ÿç©ºé—´_____ \\n\")\n",
    "print(\"çŠ¶æ€ç©ºé—´å¤§å°ä¸º: \", s_size)\n",
    "print(\"è§‚å¯Ÿæ ·æœ¬\", env.observation_space.sample()) # è·å–ä¸€ä¸ªéšæœºè§‚å¯Ÿ"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____è§‚å¯Ÿç©ºé—´_____ \n",
      "\n",
      "çŠ¶æ€ç©ºé—´å¤§å°ä¸º:  4\n",
      "è§‚å¯Ÿæ ·æœ¬ [ 1.1961311e+00 -4.3045794e+37  3.1573388e-01 -1.8938621e+38]\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lu6t4sRNNWkN",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:34:06.653736Z",
     "start_time": "2025-08-12T12:34:06.646717Z"
    }
   },
   "source": [
    "print(\"\\n _____åŠ¨ä½œç©ºé—´_____ \\n\")\n",
    "print(\"åŠ¨ä½œç©ºé—´å¤§å°ä¸º: \", a_size)\n",
    "print(\"åŠ¨ä½œç©ºé—´æ ·æœ¬\", env.action_space.sample()) # è·å–ä¸€ä¸ªéšæœºåŠ¨ä½œ"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____åŠ¨ä½œç©ºé—´_____ \n",
      "\n",
      "åŠ¨ä½œç©ºé—´å¤§å°ä¸º:  2\n",
      "åŠ¨ä½œç©ºé—´æ ·æœ¬ 1\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SJMJj3WaFOz"
   },
   "source": [
    "## è®©æˆ‘ä»¬æ„å»º Reinforce æ¶æ„\n",
    "è¿™ä¸ªå®ç°åŸºäºä¸¤ä¸ªå®ç°ï¼š\n",
    "- [PyTorch å®˜æ–¹å¼ºåŒ–å­¦ä¹ ç¤ºä¾‹](https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py)\n",
    "- [Udacity Reinforce](https://github.com/udacity/deep-reinforcement-learning/blob/master/reinforce/REINFORCE.ipynb)\n",
    "- [Chris1nexus æ”¹è¿›çš„é›†æˆ](https://github.com/huggingface/deep-rl-class/pull/95)\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit6/reinforce.png\" alt=\"Reinforce\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49kogtxBODX8"
   },
   "source": [
    "æ‰€ä»¥æˆ‘ä»¬æƒ³è¦ï¼š\n",
    "- ä¸¤ä¸ªå…¨è¿æ¥å±‚ (fc1 å’Œ fc2)ã€‚\n",
    "- ä½¿ç”¨ ReLU ä½œä¸º fc1 çš„æ¿€æ´»å‡½æ•°\n",
    "- ä½¿ç”¨ Softmax è¾“å‡ºä¸€ä¸ªå…³äºåŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w2LHcHhVZvPZ",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:31:51.063260Z",
     "start_time": "2025-08-12T18:31:51.057136Z"
    }
   },
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(Policy, self).__init__()\n",
    "        # åˆ›å»ºä¸¤ä¸ªå…¨è¿æ¥å±‚\n",
    "        self.fc1 = nn.Linear(s_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # å®šä¹‰å‰å‘ä¼ æ’­\n",
    "        # çŠ¶æ€è¿›å…¥ fc1 ç„¶åæˆ‘ä»¬åº”ç”¨ ReLU æ¿€æ´»å‡½æ•°\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # fc1 çš„è¾“å‡ºè¿›å…¥ fc2\n",
    "        x = self.fc2(x)\n",
    "        # æˆ‘ä»¬è¾“å‡º softmax\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        ç»™å®šä¸€ä¸ªçŠ¶æ€ï¼Œé‡‡å–è¡ŒåŠ¨\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        m = Categorical(probs)\n",
    "        action = np.argmax(m) # <--- è¿™é‡Œæœ‰ä¸ªé”™è¯¯!\n",
    "        return action.item(), m.log_prob(action)"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTGWL4g2eM5B"
   },
   "source": [
    "æˆ‘çŠ¯äº†ä¸€ä¸ªé”™è¯¯ï¼Œä½ èƒ½çŒœåˆ°åœ¨å“ªé‡Œå—ï¼Ÿ\n",
    "\n",
    "- ä¸ºäº†æ‰¾å‡ºç­”æ¡ˆï¼Œè®©æˆ‘ä»¬è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwnqGBCNePor"
   },
   "outputs": [],
   "source": [
    "debug_policy = Policy(s_size, a_size, 64).to(device)\n",
    "try:\n",
    "    debug_policy.act(env.reset())\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14UYkoxCPaor"
   },
   "source": [
    "- è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°é”™è¯¯æç¤º `ValueError: The value argument to log_prob must be a Tensor`\n",
    "\n",
    "- è¿™æ„å‘³ç€ `m.log_prob(action)` ä¸­çš„ `action` å¿…é¡»æ˜¯ä¸€ä¸ªå¼ é‡ **ä½†å®ƒä¸æ˜¯**ã€‚\n",
    "\n",
    "- ä½ çŸ¥é“ä¸ºä»€ä¹ˆå—ï¼Ÿæ£€æŸ¥ act å‡½æ•°ï¼Œè¯•ç€çœ‹çœ‹ä¸ºä»€ä¹ˆå®ƒä¸èµ·ä½œç”¨ã€‚\n",
    "\n",
    "æç¤º ğŸ’¡ï¼šè¿™ä¸ªå®ç°ä¸­æœ‰äº›ä¸œè¥¿æ˜¯é”™çš„ã€‚è®°ä½ï¼Œ`act` å‡½æ•°**æˆ‘ä»¬æƒ³è¦ä»åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªåŠ¨ä½œ**ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfGJNZBUP7Vn"
   },
   "source": [
    "### (çœŸæ­£çš„) è§£å†³æ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ho_UHf49N9i4",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:31:54.630364Z",
     "start_time": "2025-08-12T18:31:54.624445Z"
    }
   },
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(Policy, self).__init__()\n",
    "        self.fc1 = nn.Linear(s_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample() # <-- æ­£ç¡®çš„æ–¹æ³•æ˜¯é‡‡æ ·!\n",
    "        return action.item(), m.log_prob(action)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgJWQFU_eUYw"
   },
   "source": [
    "é€šè¿‡ä½¿ç”¨ CartPoleï¼Œè°ƒè¯•å˜å¾—æ›´å®¹æ˜“ï¼Œå› ä¸º**æˆ‘ä»¬çŸ¥é“é”™è¯¯æ¥è‡ªæˆ‘ä»¬çš„é›†æˆï¼Œè€Œä¸æ˜¯æ¥è‡ªæˆ‘ä»¬çš„ç®€å•ç¯å¢ƒ**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- å› ä¸º**æˆ‘ä»¬æƒ³ä»åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªåŠ¨ä½œ**ï¼Œæˆ‘ä»¬ä¸èƒ½ä½¿ç”¨ `action = np.argmax(m)`ï¼Œå› ä¸ºå®ƒæ€»æ˜¯ä¼šè¾“å‡ºæ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œã€‚\n",
    "\n",
    "- æˆ‘ä»¬éœ€è¦ç”¨ `action = m.sample()` æ¥æ›¿æ¢ï¼Œå®ƒå°†ä»æ¦‚ç‡åˆ†å¸ƒ P(.|s) ä¸­é‡‡æ ·ä¸€ä¸ªåŠ¨ä½œ"
   ],
   "metadata": {
    "id": "c-20i7Pk0l1T"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MXoqetzfIoW"
   },
   "source": [
    "### è®©æˆ‘ä»¬æ„å»º Reinforce è®­ç»ƒç®—æ³•\n",
    "è¿™æ˜¯ Reinforce ç®—æ³•çš„ä¼ªä»£ç ï¼š\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit6/pg_pseudocode.png\" alt=\"Policy gradient pseudocode\"/>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- å½“æˆ‘ä»¬è®¡ç®—å›æŠ¥ Gt (ä¼ªä»£ç ç¬¬ 6 è¡Œ) æ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬è®¡ç®—çš„æ˜¯**ä»æ—¶é—´æ­¥ t å¼€å§‹**çš„æŠ˜æ‰£å¥–åŠ±æ€»å’Œã€‚\n",
    "\n",
    "- ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºæˆ‘ä»¬çš„ç­–ç•¥åº”è¯¥åª**æ ¹æ®åæœæ¥å¼ºåŒ–åŠ¨ä½œ**ï¼šæ‰€ä»¥åœ¨é‡‡å–ä¸€ä¸ªåŠ¨ä½œä¹‹å‰è·å¾—çš„å¥–åŠ±æ˜¯æ— ç”¨çš„ï¼ˆå› ä¸ºå®ƒä»¬ä¸æ˜¯ç”±è¯¥åŠ¨ä½œå¼•èµ·çš„ï¼‰ï¼Œ**åªæœ‰åœ¨åŠ¨ä½œä¹‹åå‘ç”Ÿçš„å¥–åŠ±æ‰é‡è¦**ã€‚\n",
    "\n",
    "- åœ¨ç¼–å†™ä»£ç ä¹‹å‰ï¼Œä½ åº”è¯¥é˜…è¯»è¿™ä¸€éƒ¨åˆ† [ä¸è¦è®©è¿‡å»åˆ†æ•£ä½ çš„æ³¨æ„åŠ›](https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html#don-t-let-the-past-distract-you)ï¼Œå®ƒè§£é‡Šäº†æˆ‘ä»¬ä¸ºä»€ä¹ˆä½¿ç”¨ â€œæœªæ¥å¥–åŠ±â€(reward-to-go) ç­–ç•¥æ¢¯åº¦ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ä¸€ç§ç”± [Chris1nexus](https://github.com/Chris1nexus) ç¼–å†™çš„æœ‰è¶£æŠ€æœ¯æ¥**é«˜æ•ˆåœ°è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„å›æŠ¥**ã€‚æ³¨é‡Šè§£é‡Šäº†è¯¥è¿‡ç¨‹ã€‚ä¹Ÿè¯·éšæ—¶[æŸ¥çœ‹ PR çš„è§£é‡Š](https://github.com/huggingface/deep-rl-class/pull/95)\n",
    "ä½†æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªæƒ³æ³•æ˜¯**é«˜æ•ˆåœ°è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„å›æŠ¥**ã€‚"
   ],
   "metadata": {
    "id": "QmcXG-9i2Qu2"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O554nUGPpcoq"
   },
   "source": [
    "ä½ å¯èƒ½ä¼šé—®çš„ç¬¬äºŒä¸ªé—®é¢˜æ˜¯**ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦æœ€å°åŒ–æŸå¤±**ï¼Ÿä½ è¯´çš„æ˜¯æ¢¯åº¦ä¸Šå‡è€Œä¸æ˜¯æ¢¯åº¦ä¸‹é™ï¼Ÿ\n",
    "\n",
    "- æˆ‘ä»¬æƒ³è¦æœ€å¤§åŒ–æˆ‘ä»¬çš„æ•ˆç”¨å‡½æ•° $J(\\theta)$ï¼Œä½†åœ¨ PyTorch ä¸­ï¼Œå°±åƒåœ¨ Tensorflow ä¸­ä¸€æ ·ï¼Œæœ€å¥½æ˜¯**æœ€å°åŒ–ä¸€ä¸ªç›®æ ‡å‡½æ•°ã€‚**\n",
    "    - æ‰€ä»¥ï¼Œå‡è®¾æˆ‘ä»¬æƒ³åœ¨æŸä¸ªæ—¶é—´æ­¥å¼ºåŒ–åŠ¨ä½œ 3ã€‚è®­ç»ƒå‰ï¼Œè¿™ä¸ªåŠ¨ä½œçš„æ¦‚ç‡ P æ˜¯ 0.25ã€‚\n",
    "    - æ‰€ä»¥æˆ‘ä»¬æƒ³è¦ä¿®æ”¹ $\\theta$ ä½¿å¾— $\\pi_\\theta(a_3|s; \\theta) > 0.25$\n",
    "    - å› ä¸ºæ‰€æœ‰çš„æ¦‚ç‡ P ä¹‹å’Œå¿…é¡»ä¸º 1ï¼Œæœ€å¤§åŒ– $\\pi_\\theta(a_3|s; \\theta)$ å°†**æœ€å°åŒ–å…¶ä»–åŠ¨ä½œçš„æ¦‚ç‡ã€‚**\n",
    "    - æ‰€ä»¥æˆ‘ä»¬åº”è¯¥å‘Šè¯‰ PyTorch **æœ€å°åŒ– $1 - \\pi_\\theta(a_3|s; \\theta)$ã€‚**\n",
    "    - å½“ $\\pi_\\theta(a_3|s; \\theta)$ æ¥è¿‘ 1 æ—¶ï¼Œè¿™ä¸ªæŸå¤±å‡½æ•°è¶‹è¿‘äº 0ã€‚\n",
    "    - æ‰€ä»¥æˆ‘ä»¬æ˜¯åœ¨é¼“åŠ±æ¢¯åº¦å»æœ€å¤§åŒ– $\\pi_\\theta(a_3|s; \\theta)$ã€‚\n",
    "\n",
    "åœ¨æˆ‘ä»¬çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬ä¸æœ€å°åŒ– $1 - \\pi_\\theta(a_t|s_t)$ï¼Œè€Œæ˜¯æœ€å°åŒ– $-\\log \\pi_\\theta(a_t|s_t) * G_t$ã€‚è¿™åœ¨æ•ˆæœä¸Šæ˜¯ç›¸åŒçš„ï¼šæˆ‘ä»¬æƒ³å¢åŠ ä¸€ä¸ªåŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡ï¼Œè€Œè¿™ä¸ªåŠ¨ä½œä¼šå¸¦æ¥é«˜çš„å›æŠ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iOdv8Q9NfLK7",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:34:15.832305Z",
     "start_time": "2025-08-12T12:34:15.821236Z"
    }
   },
   "source": [
    "def reinforce(policy, optimizer, n_training_episodes, max_t, gamma, print_every):\n",
    "    # å¸®åŠ©æˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´è®¡ç®—åˆ†æ•°\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    # ä¼ªä»£ç ç¬¬ 3 è¡Œ\n",
    "    for i_episode in range(1, n_training_episodes+1):\n",
    "        saved_log_probs = []\n",
    "        rewards = []\n",
    "        state = env.reset() # TODO: é‡ç½®ç¯å¢ƒ\n",
    "        # ä¼ªä»£ç ç¬¬ 4 è¡Œ\n",
    "        for t in range(max_t):\n",
    "            action, log_prob = policy.act(state) # TODO: è·å–åŠ¨ä½œ\n",
    "            saved_log_probs.append(log_prob)\n",
    "            state, reward, done, _ = env.step(action) # TODO: åœ¨ç¯å¢ƒä¸­æ‰§è¡Œä¸€æ­¥\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "        scores_deque.append(sum(rewards))\n",
    "        scores.append(sum(rewards))\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬ 6 è¡Œï¼šè®¡ç®—å›æŠ¥\n",
    "        returns = deque(maxlen=max_t)\n",
    "        n_steps = len(rewards)\n",
    "        \n",
    "        # ä»åå‘å‰è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„æŠ˜æ‰£å›æŠ¥\n",
    "        # G_t = r_t + gamma * G_{t+1}\n",
    "        # G_{T-1} = r_{T-1} (å…¶ä¸­ T æ˜¯å›åˆçš„æœ€åä¸€æ­¥)\n",
    "        # è¿™ç§æ–¹æ³•ï¼ˆåŠ¨æ€è§„åˆ’ï¼‰å¯ä»¥æœ‰æ•ˆåœ°é‡ç”¨è®¡ç®—è¿‡çš„æœªæ¥å›æŠ¥\n",
    "        # é¿å…äº† O(N^2) çš„æœ´ç´ è®¡ç®—\n",
    "        \n",
    "        # æˆ‘ä»¬ä»æœ€åä¸€ä¸ªæ—¶é—´æ­¥å¼€å§‹å‘ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥è®¡ç®—ï¼Œ\n",
    "        # ä»¥ä¾¿åˆ©ç”¨ä¸Šé¢ä»‹ç»çš„å…¬å¼ï¼Œé¿å…ä¸å¿…è¦çš„é‡å¤è®¡ç®—ã€‚\n",
    "        # å› æ­¤ï¼Œé˜Ÿåˆ— `returns` å°†æŒ‰æ—¶é—´é¡ºåºå­˜å‚¨å›æŠ¥ï¼Œä» t=0 åˆ° t=n_steps\n",
    "        # è¿™è¦å½’åŠŸäº appendleft() å‡½æ•°ï¼Œå®ƒå…è®¸ä»¥ O(1) çš„å¸¸æ•°æ—¶é—´åœ¨ä½ç½® 0 å¤„è¿½åŠ \n",
    "        # è€Œæ™®é€šçš„ python åˆ—è¡¨åˆ™éœ€è¦ O(N) çš„æ—¶é—´æ¥å®Œæˆæ­¤æ“ä½œã€‚\n",
    "        for t in range(n_steps)[::-1]:\n",
    "            disc_return_t = (returns[0] if len(returns)>0 else 0)\n",
    "            returns.appendleft(rewards[t] + gamma * disc_return_t) # TODO: åœ¨è¿™é‡Œå®Œæˆ\n",
    "\n",
    "        ## æ ‡å‡†åŒ–å›æŠ¥å¯ä»¥ä½¿è®­ç»ƒæ›´ç¨³å®š\n",
    "        eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "        ## eps æ˜¯æœ€å°çš„å¯è¡¨ç¤ºæµ®ç‚¹æ•°ï¼Œ\n",
    "        # å°†å…¶æ·»åŠ åˆ°å›æŠ¥çš„æ ‡å‡†å·®ä¸­ä»¥é¿å…æ•°å€¼ä¸ç¨³å®š\n",
    "        returns = torch.tensor(list(returns))\n",
    "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬ 7 è¡Œï¼šè®¡ç®—ç­–ç•¥æŸå¤±\n",
    "        policy_loss = []\n",
    "        for log_prob, disc_return in zip(saved_log_probs, returns):\n",
    "            policy_loss.append(-log_prob * disc_return)\n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬ 8 è¡Œï¼šPyTorch åå¥½æ¢¯åº¦ä¸‹é™\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            print('å›åˆ {}\\tå¹³å‡åˆ†æ•°: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "\n",
    "    return scores"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YB0Cxrw1StrP"
   },
   "source": [
    "#### è§£å†³æ–¹æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NCNvyElRStWG",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:32:02.624063Z",
     "start_time": "2025-08-12T18:32:02.615605Z"
    }
   },
   "source": [
    "def reinforce(policy, optimizer, n_training_episodes, max_t, gamma, print_every):\n",
    "    # å¸®åŠ©æˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´è®¡ç®—åˆ†æ•°\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    # ä¼ªä»£ç ç¬¬ 3 è¡Œ\n",
    "    for i_episode in range(1, n_training_episodes+1):\n",
    "        saved_log_probs = []\n",
    "        rewards = []\n",
    "        state = env.reset()\n",
    "        # ä¼ªä»£ç ç¬¬ 4 è¡Œ\n",
    "        for t in range(max_t):\n",
    "            action, log_prob = policy.act(state)\n",
    "            saved_log_probs.append(log_prob)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "        scores_deque.append(sum(rewards))\n",
    "        scores.append(sum(rewards))\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬ 6 è¡Œï¼šè®¡ç®—å›æŠ¥\n",
    "        returns = deque(maxlen=max_t)\n",
    "        n_steps = len(rewards)\n",
    "        \n",
    "        # ä»åå‘å‰è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„æŠ˜æ‰£å›æŠ¥\n",
    "        # G_t = r_t + gamma * G_{t+1}\n",
    "        # G_{T-1} = r_{T-1} (å…¶ä¸­ T æ˜¯å›åˆçš„æœ€åä¸€æ­¥)\n",
    "        # è¿™ç§æ–¹æ³•ï¼ˆåŠ¨æ€è§„åˆ’ï¼‰å¯ä»¥æœ‰æ•ˆåœ°é‡ç”¨è®¡ç®—è¿‡çš„æœªæ¥å›æŠ¥\n",
    "        # é¿å…äº† O(N^2) çš„æœ´ç´ è®¡ç®—\n",
    "        for t in range(n_steps)[::-1]:\n",
    "            disc_return_t = (returns[0] if len(returns)>0 else 0)\n",
    "            returns.appendleft(rewards[t] + gamma * disc_return_t)\n",
    "\n",
    "        ## æ ‡å‡†åŒ–å›æŠ¥å¯ä»¥ä½¿è®­ç»ƒæ›´ç¨³å®š\n",
    "        eps = np.finfo(np.float32).eps.item()\n",
    "        ## eps æ˜¯æœ€å°çš„å¯è¡¨ç¤ºæµ®ç‚¹æ•°ï¼Œ\n",
    "        # å°†å…¶æ·»åŠ åˆ°å›æŠ¥çš„æ ‡å‡†å·®ä¸­ä»¥é¿å…æ•°å€¼ä¸ç¨³å®š\n",
    "        returns = torch.tensor(list(returns))\n",
    "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬ 7 è¡Œï¼šè®¡ç®—ç­–ç•¥æŸå¤±\n",
    "        policy_loss = []\n",
    "        for log_prob, disc_return in zip(saved_log_probs, returns):\n",
    "            policy_loss.append(-log_prob * disc_return)\n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬ 8 è¡Œï¼šPyTorch åå¥½æ¢¯åº¦ä¸‹é™\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            print('å›åˆ {}\\tå¹³å‡åˆ†æ•°: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "\n",
    "    return scores"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIWhQyJjfpEt"
   },
   "source": [
    "## è®­ç»ƒå®ƒ\n",
    "- æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½è®­ç»ƒæˆ‘ä»¬çš„æ™ºèƒ½ä½“äº†ã€‚\n",
    "- ä½†é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåŒ…å«æ‰€æœ‰è®­ç»ƒè¶…å‚æ•°çš„å˜é‡ã€‚\n",
    "- ä½ å¯ä»¥ï¼ˆä¹Ÿåº”è¯¥ ğŸ˜‰ï¼‰æ›´æ”¹è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utRe1NgtVBYF"
   },
   "outputs": [],
   "source": [
    "cartpole_hyperparameters = {\n",
    "    \"h_size\": 16, # éšè—å±‚å¤§å°\n",
    "    \"n_training_episodes\": 1000, # è®­ç»ƒå›åˆæ•°\n",
    "    \"n_evaluation_episodes\": 10, # è¯„ä¼°å›åˆæ•°\n",
    "    \"max_t\": 1000, # æ¯ä¸ªå›åˆçš„æœ€å¤§æ­¥æ•°\n",
    "    \"gamma\": 1.0, # æŠ˜æ‰£å› å­\n",
    "    \"lr\": 1e-2, # å­¦ä¹ ç‡\n",
    "    \"env_id\": env_id,\n",
    "    \"state_space\": s_size,\n",
    "    \"action_space\": a_size,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3lWyVXBVfl6"
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºç­–ç•¥å¹¶å°†å…¶æ”¾ç½®åˆ°è®¾å¤‡ä¸Š\n",
    "cartpole_policy = Policy(cartpole_hyperparameters[\"state_space\"], cartpole_hyperparameters[\"action_space\"], cartpole_hyperparameters[\"h_size\"]).to(device)\n",
    "cartpole_optimizer = optim.Adam(cartpole_policy.parameters(), lr=cartpole_hyperparameters[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGf-hQCnfouB"
   },
   "outputs": [],
   "source": [
    "scores = reinforce(cartpole_policy,\n",
    "                   cartpole_optimizer,\n",
    "                   cartpole_hyperparameters[\"n_training_episodes\"],\n",
    "                   cartpole_hyperparameters[\"max_t\"],\n",
    "                   cartpole_hyperparameters[\"gamma\"],\n",
    "                   100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qajj2kXqhB3g"
   },
   "source": [
    "## å®šä¹‰è¯„ä¼°æ–¹æ³• ğŸ“\n",
    "- åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰å°†ç”¨äºæµ‹è¯•æˆ‘ä»¬çš„ Reinforce æ™ºèƒ½ä½“çš„è¯„ä¼°æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3FamHmxyhBEU",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:37:39.664220Z",
     "start_time": "2025-08-12T18:37:39.657718Z"
    }
   },
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, policy):\n",
    "  \"\"\"\n",
    "  åœ¨ n_eval_episodes ä¸ªå›åˆä¸­è¯„ä¼°æ™ºèƒ½ä½“ï¼Œå¹¶è¿”å›å¹³å‡å¥–åŠ±å’Œå¥–åŠ±çš„æ ‡å‡†å·®ã€‚\n",
    "  :param env: è¯„ä¼°ç¯å¢ƒ\n",
    "  :param n_eval_episodes: è¯„ä¼°æ™ºèƒ½ä½“çš„å›åˆæ•°\n",
    "  :param policy: Reinforce æ™ºèƒ½ä½“\n",
    "  \"\"\"\n",
    "  episode_rewards = []\n",
    "  for episode in range(n_eval_episodes):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards_ep = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "      action, _ = policy.act(state)\n",
    "      new_state, reward, done, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "\n",
    "      if done:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdH2QCrLTrlT"
   },
   "source": [
    "## è¯„ä¼°æˆ‘ä»¬çš„æ™ºèƒ½ä½“ ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ohGSXDyHh0xx",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:33:09.119339Z",
     "start_time": "2025-08-12T18:33:09.081784Z"
    }
   },
   "source": [
    "evaluate_agent(eval_env,\n",
    "               cartpole_hyperparameters[\"max_t\"],\n",
    "               cartpole_hyperparameters[\"n_evaluation_episodes\"],\n",
    "               cartpole_policy)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cartpole_hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[52]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m evaluate_agent(eval_env,\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m                cartpole_hyperparameters[\u001B[33m\"\u001B[39m\u001B[33mmax_t\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m      3\u001B[39m                cartpole_hyperparameters[\u001B[33m\"\u001B[39m\u001B[33mn_evaluation_episodes\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m      4\u001B[39m                cartpole_policy)\n",
      "\u001B[31mNameError\u001B[39m: name 'cartpole_hyperparameters' is not defined"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CoeLkQ7TpO8"
   },
   "source": [
    "### åœ¨ Hub ä¸Šå‘å¸ƒæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹ ğŸ”¥\n",
    "ç°åœ¨æˆ‘ä»¬çœ‹åˆ°è®­ç»ƒåå–å¾—äº†ä¸é”™çš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€è¡Œä»£ç å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹å‘å¸ƒåˆ° Hub ä¸Š ğŸ¤—ã€‚\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªæ¨¡å‹å¡çš„ç¤ºä¾‹ï¼š\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit6/modelcard.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmhs1k-cftIq"
   },
   "source": [
    "### æ¨é€åˆ° Hub\n",
    "#### ä¸è¦ä¿®æ”¹æ­¤ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import HfApi, snapshot_download\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json\n",
    "import imageio\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import os"
   ],
   "metadata": {
    "id": "LIVsvlW_8tcw",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:33:16.710690Z",
     "start_time": "2025-08-12T18:33:16.705800Z"
    }
   },
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lo4JH45if81z",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:33:18.537400Z",
     "start_time": "2025-08-12T18:33:18.531729Z"
    }
   },
   "source": [
    "def record_video(env, policy, out_directory, fps=30):\n",
    "  \"\"\"\n",
    "  ç”Ÿæˆæ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘\n",
    "  :param env\n",
    "  :param policy: æˆ‘ä»¬æ™ºèƒ½ä½“çš„ç­–ç•¥\n",
    "  :param out_directory\n",
    "  :param fps: æ¯ç§’å¸§æ•°\n",
    "  \"\"\"\n",
    "  images = []\n",
    "  done = False\n",
    "  state = env.reset()\n",
    "  img = env.render(mode='rgb_array')\n",
    "  images.append(img)\n",
    "  while not done:\n",
    "    # æ ¹æ®ç»™å®šçŠ¶æ€é‡‡å–å…·æœ‰æœ€å¤§é¢„æœŸæœªæ¥å¥–åŠ±çš„åŠ¨ä½œ\n",
    "    action, _ = policy.act(state)\n",
    "    state, reward, done, info = env.step(action) # ä¸ºäº†å½•åˆ¶é€»è¾‘ï¼Œæˆ‘ä»¬ç›´æ¥å°† next_state = state\n",
    "    img = env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": [
    "def push_to_hub(repo_id,\n",
    "                model,\n",
    "                hyperparameters,\n",
    "                eval_env,\n",
    "                video_fps=30\n",
    "                ):\n",
    "  \"\"\"\n",
    "  è¯„ä¼°ã€ç”Ÿæˆè§†é¢‘å¹¶ä¸Šä¼ æ¨¡å‹åˆ° Hugging Face Hubã€‚\n",
    "  æ­¤æ–¹æ³•å®Œæˆæ•´ä¸ªæµç¨‹ï¼š\n",
    "  - è¯„ä¼°æ¨¡å‹\n",
    "  - ç”Ÿæˆæ¨¡å‹å¡\n",
    "  - ç”Ÿæˆæ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘\n",
    "  - å°†æ‰€æœ‰å†…å®¹æ¨é€åˆ° Hub\n",
    "\n",
    "  :param repo_id: Hugging Face Hub ä¸Šçš„æ¨¡å‹ä»“åº“ ID\n",
    "  :param model: æˆ‘ä»¬æƒ³è¦ä¿å­˜çš„ PyTorch æ¨¡å‹\n",
    "  :param hyperparameters: è®­ç»ƒè¶…å‚æ•°\n",
    "  :param eval_env: è¯„ä¼°ç¯å¢ƒ\n",
    "  :param video_fps: å½•åˆ¶è§†é¢‘å›æ”¾çš„æ¯ç§’å¸§æ•°\n",
    "  \"\"\"\n",
    "\n",
    "  _, repo_name = repo_id.split(\"/\")\n",
    "  api = HfApi()\n",
    "\n",
    "  # æ­¥éª¤ 1: åˆ›å»ºä»“åº“\n",
    "  repo_url = api.create_repo(\n",
    "        repo_id=repo_id,\n",
    "        exist_ok=True,\n",
    "  )\n",
    "\n",
    "  with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    local_directory = Path(tmpdirname)\n",
    "\n",
    "    # æ­¥éª¤ 2: ä¿å­˜æ¨¡å‹\n",
    "    torch.save(model, local_directory / \"model.pt\")\n",
    "\n",
    "    # æ­¥éª¤ 3: å°†è¶…å‚æ•°ä¿å­˜åˆ° JSON\n",
    "    with open(local_directory / \"hyperparameters.json\", \"w\") as outfile:\n",
    "      json.dump(hyperparameters, outfile)\n",
    "\n",
    "    # æ­¥éª¤ 4: è¯„ä¼°æ¨¡å‹å¹¶æ„å»º JSON\n",
    "    mean_reward, std_reward = evaluate_agent(eval_env,\n",
    "                                            hyperparameters[\"max_t\"],\n",
    "                                            hyperparameters[\"n_evaluation_episodes\"],\n",
    "                                            model)\n",
    "    # è·å–æ—¥æœŸæ—¶é—´\n",
    "    eval_datetime = datetime.datetime.now()\n",
    "    eval_form_datetime = eval_datetime.isoformat()\n",
    "\n",
    "    evaluate_data = {\n",
    "          \"env_id\": hyperparameters[\"env_id\"],\n",
    "          \"mean_reward\": mean_reward,\n",
    "          \"n_evaluation_episodes\": hyperparameters[\"n_evaluation_episodes\"],\n",
    "          \"eval_datetime\": eval_form_datetime,\n",
    "    }\n",
    "\n",
    "    # å†™å…¥ JSON æ–‡ä»¶\n",
    "    with open(local_directory / \"results.json\", \"w\") as outfile:\n",
    "        json.dump(evaluate_data, outfile)\n",
    "\n",
    "    # æ­¥éª¤ 5: åˆ›å»ºæ¨¡å‹å¡\n",
    "    env_name = hyperparameters[\"env_id\"]\n",
    "\n",
    "    metadata = {}\n",
    "    metadata[\"tags\"] = [\n",
    "          env_name,\n",
    "          \"reinforce\",\n",
    "          \"reinforcement-learning\",\n",
    "          \"custom-implementation\",\n",
    "          \"deep-rl-class\"\n",
    "      ]\n",
    "\n",
    "    # æ·»åŠ æŒ‡æ ‡\n",
    "    eval = metadata_eval_result(\n",
    "        model_pretty_name=repo_name,\n",
    "        task_pretty_name=\"reinforcement-learning\",\n",
    "        task_id=\"reinforcement-learning\",\n",
    "        metrics_pretty_name=\"mean_reward\",\n",
    "        metrics_id=\"mean_reward\",\n",
    "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
    "        dataset_pretty_name=env_name,\n",
    "        dataset_id=env_name,\n",
    "      )\n",
    "\n",
    "    # åˆå¹¶ä¸¤ä¸ªå­—å…¸\n",
    "    metadata = {**metadata, **eval}\n",
    "\n",
    "    model_card = f\"\"\"\n",
    "  # **Reinforce** æ™ºèƒ½ä½“ç© **{env_id}**\n",
    "  è¿™æ˜¯ä¸€ä¸ªè®­ç»ƒå¥½çš„ **Reinforce** æ™ºèƒ½ä½“ç© **{env_id}** çš„æ¨¡å‹ã€‚\n",
    "  è¦å­¦ä¹ å¦‚ä½•ä½¿ç”¨æ­¤æ¨¡å‹å¹¶è®­ç»ƒä½ è‡ªå·±çš„æ¨¡å‹ï¼Œè¯·æŸ¥çœ‹æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹çš„ç¬¬ 4 å•å…ƒï¼šhttps://huggingface.co/deep-rl-course/unit4/introduction\n",
    "  \"\"\"\n",
    "\n",
    "    readme_path = local_directory / \"README.md\"\n",
    "    readme = \"\"\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
    "          readme = f.read()\n",
    "    else:\n",
    "      readme = model_card\n",
    "\n",
    "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "      f.write(readme)\n",
    "\n",
    "    # å°†æˆ‘ä»¬çš„æŒ‡æ ‡ä¿å­˜åˆ° Readme å…ƒæ•°æ®ä¸­\n",
    "    metadata_save(readme_path, metadata)\n",
    "\n",
    "    # æ­¥éª¤ 6: å½•åˆ¶è§†é¢‘\n",
    "    video_path =  local_directory / \"replay.mp4\"\n",
    "    record_video(eval_env, model, video_path, video_fps)\n",
    "\n",
    "    # æ­¥éª¤ 7: å°†æ‰€æœ‰å†…å®¹æ¨é€åˆ° Hub\n",
    "    api.upload_folder(\n",
    "          repo_id=repo_id,\n",
    "          folder_path=local_directory,\n",
    "          path_in_repo=\".\",\n",
    "    )\n",
    "\n",
    "    print(f\"ä½ çš„æ¨¡å‹å·²æ¨é€åˆ° Hubã€‚ä½ å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹ä½ çš„æ¨¡å‹ï¼š{repo_url}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T18:33:20.854706Z",
     "start_time": "2025-08-12T18:33:20.843722Z"
    }
   },
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w17w8CxzoURM"
   },
   "source": [
    "é€šè¿‡ä½¿ç”¨ `push_to_hub`ï¼Œä½ **è¯„ä¼°ã€å½•åˆ¶å›æ”¾ã€ç”Ÿæˆæ™ºèƒ½ä½“çš„æ¨¡å‹å¡å¹¶å°†å…¶æ¨é€åˆ° Hub**ã€‚\n",
    "\n",
    "è¿™æ ·ï¼š\n",
    "- ä½ å¯ä»¥**å±•ç¤ºæˆ‘ä»¬çš„å·¥ä½œ** ğŸ”¥\n",
    "- ä½ å¯ä»¥**å¯è§†åŒ–ä½ çš„æ™ºèƒ½ä½“ç©æ¸¸æˆ** ğŸ‘€\n",
    "- ä½ å¯ä»¥**ä¸ç¤¾åŒºå…±äº«ä¸€ä¸ªå…¶ä»–äººå¯ä»¥ä½¿ç”¨çš„æ™ºèƒ½ä½“** ğŸ’¾\n",
    "- ä½ å¯ä»¥**è®¿é—®ä¸€ä¸ªæ’è¡Œæ¦œ ğŸ† æ¥çœ‹çœ‹ä½ çš„æ™ºèƒ½ä½“ä¸åŒå­¦ç›¸æ¯”è¡¨ç°å¦‚ä½•** ğŸ‘‰ https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWnFC0iZooTw"
   },
   "source": [
    "ä¸ºäº†èƒ½å¤Ÿä¸ç¤¾åŒºå…±äº«ä½ çš„æ¨¡å‹ï¼Œè¿˜éœ€è¦éµå¾ªä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "1ï¸âƒ£ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰åœ¨ HF ä¸Šåˆ›å»ºä¸€ä¸ªå¸æˆ· â¡ https://huggingface.co/join\n",
    "\n",
    "2ï¸âƒ£ ç™»å½•ï¼Œç„¶åï¼Œä½ éœ€è¦ä» Hugging Face ç½‘ç«™å­˜å‚¨ä½ çš„èº«ä»½éªŒè¯ä»¤ç‰Œã€‚\n",
    "- åˆ›å»ºä¸€ä¸ªæ–°ä»¤ç‰Œ (https://huggingface.co/settings/tokens) **å¹¶èµ‹äºˆå†™å…¥è§’è‰²**\n",
    "\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QB5nIcxR8paT",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:33:26.303682Z",
     "start_time": "2025-08-12T18:33:26.292696Z"
    }
   },
   "source": [
    "notebook_login()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bd5376278ff4230b93f0547d9336a3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyWc1x3-o3xG"
   },
   "source": [
    "å¦‚æœä½ ä¸æƒ³ä½¿ç”¨ Jupyter Notebookï¼Œä½ éœ€è¦æ”¹ç”¨è¿™ä¸ªå‘½ä»¤ï¼š`huggingface-cli login`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-D-zhbRoeOm"
   },
   "source": [
    "3ï¸âƒ£ æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½ä½¿ç”¨ `push_to_hub()` å‡½æ•°å°†æˆ‘ä»¬è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“æ¨é€åˆ° ğŸ¤— Hub ğŸ”¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNwkTS65Uq3Q"
   },
   "outputs": [],
   "source": [
    "# TODO: å®šä¹‰ä½ çš„ repo_id {ä½ çš„ç”¨æˆ·å/Reinforce-CartPole-v1}\n",
    "# ä¾‹å¦‚ï¼šrepo_id = \"ThomasSimonini/Reinforce-CartPole-v1\"\n",
    "repo_id = \"\" \n",
    "push_to_hub(repo_id,\n",
    "                cartpole_policy, # æˆ‘ä»¬æƒ³è¦ä¿å­˜çš„æ¨¡å‹\n",
    "                cartpole_hyperparameters, # è¶…å‚æ•°\n",
    "                eval_env, # è¯„ä¼°ç¯å¢ƒ\n",
    "                video_fps=30\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrnuKH1gYZSz"
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬å·²ç»æµ‹è¯•äº†æˆ‘ä»¬å®ç°çš„é²æ£’æ€§ï¼Œè®©æˆ‘ä»¬å°è¯•ä¸€ä¸ªæ›´å¤æ‚çš„ç¯å¢ƒï¼šPixelCopter ğŸš\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ç¬¬äºŒä¸ªæ™ºèƒ½ä½“ï¼šPixelCopter ğŸš\n",
    "\n",
    "### ç ”ç©¶ PixelCopter ç¯å¢ƒ ğŸ‘€\n",
    "- [ç¯å¢ƒæ–‡æ¡£](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pixelcopter.html)\n"
   ],
   "metadata": {
    "id": "JNLVmKKVKA6j"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JBSc8mlfyin3",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:28:17.856491Z",
     "start_time": "2025-08-12T18:28:17.847420Z"
    }
   },
   "source": [
    "env_id = \"Pixelcopter-PLE-v0\"\n",
    "env = gym.make(env_id)\n",
    "eval_env = gym.make(env_id)\n",
    "s_size = env.observation_space.shape[0]\n",
    "a_size = env.action_space.n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"_____è§‚å¯Ÿç©ºé—´_____ \\n\")\n",
    "print(\"çŠ¶æ€ç©ºé—´å¤§å°ä¸º: \", s_size)\n",
    "print(\"è§‚å¯Ÿæ ·æœ¬\", env.observation_space.sample()) # è·å–ä¸€ä¸ªéšæœºè§‚å¯Ÿ"
   ],
   "metadata": {
    "id": "L5u_zAHsKBy7",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:34:54.758823Z",
     "start_time": "2025-08-12T12:34:54.753542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____è§‚å¯Ÿç©ºé—´_____ \n",
      "\n",
      "çŠ¶æ€ç©ºé—´å¤§å°ä¸º:  7\n",
      "è§‚å¯Ÿæ ·æœ¬ [-0.04964773 -1.9876798  -0.75425804  1.433291   -0.6352314  -0.887026\n",
      "  0.86039406]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n _____åŠ¨ä½œç©ºé—´_____ \\n\")\n",
    "print(\"åŠ¨ä½œç©ºé—´å¤§å°ä¸º: \", a_size)\n",
    "print(\"åŠ¨ä½œç©ºé—´æ ·æœ¬\", env.action_space.sample()) # è·å–ä¸€ä¸ªéšæœºåŠ¨ä½œ"
   ],
   "metadata": {
    "id": "D7yJM9YXKNbq",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:34:56.341535Z",
     "start_time": "2025-08-12T12:34:56.332215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____åŠ¨ä½œç©ºé—´_____ \n",
      "\n",
      "åŠ¨ä½œç©ºé—´å¤§å°ä¸º:  2\n",
      "åŠ¨ä½œç©ºé—´æ ·æœ¬ 1\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNWvlyvzalXr"
   },
   "source": [
    "è§‚å¯Ÿç©ºé—´ (7) ğŸ‘€:\n",
    "- ç©å®¶ y åæ ‡\n",
    "- ç©å®¶é€Ÿåº¦\n",
    "- ç©å®¶åˆ°åœ°é¢çš„è·ç¦»\n",
    "- ç©å®¶åˆ°å¤©èŠ±æ¿çš„è·ç¦»\n",
    "- ä¸‹ä¸€ä¸ªéšœç¢ç‰©ä¸ç©å®¶çš„ x è·ç¦»\n",
    "- ä¸‹ä¸€ä¸ªéšœç¢ç‰©é¡¶éƒ¨ y åæ ‡\n",
    "- ä¸‹ä¸€ä¸ªéšœç¢ç‰©åº•éƒ¨ y åæ ‡\n",
    "\n",
    "åŠ¨ä½œç©ºé—´(2) ğŸ®:\n",
    "- å‘ä¸Š (æŒ‰ä¸‹åŠ é€Ÿå™¨)\n",
    "- ä»€ä¹ˆéƒ½ä¸åš (ä¸æŒ‰åŠ é€Ÿå™¨)\n",
    "\n",
    "å¥–åŠ±å‡½æ•° ğŸ’°:\n",
    "- æ¯é€šè¿‡ä¸€ä¸ªå‚ç›´éšœç¢ç‰©ï¼Œå®ƒä¼šè·å¾— +1 çš„æ­£å¥–åŠ±ã€‚æ¯æ¬¡è¾¾åˆ°ç»ˆæ­¢çŠ¶æ€ï¼Œå®ƒä¼šæ”¶åˆ° -1 çš„è´Ÿå¥–åŠ±ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### å®šä¹‰æ–°çš„ç­–ç•¥ ğŸ§ \n",
    "- ç”±äºç¯å¢ƒæ›´å¤æ‚ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ›´æ·±å±‚çš„ç¥ç»ç½‘ç»œ"
   ],
   "metadata": {
    "id": "aV1466QP8crz"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I1eBkCiX2X_S",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:34:59.179712Z",
     "start_time": "2025-08-12T12:34:59.172597Z"
    }
   },
   "source": [
    "# åœ¨è¿™é‡Œå®šä¹‰ä¸€ä¸ªæ–°çš„ç­–ç•¥ç±»\n",
    "# ä¸ CartPole ä¸åŒï¼ŒPixelCopter æ›´å¤æ‚\n",
    "# æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªå…·æœ‰ä¸‰å±‚çš„æ›´æ·±å±‚ç½‘ç»œ\n",
    "class PixelCopterPolicy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(PixelCopterPolicy, self).__init__()\n",
    "        # åœ¨è¿™é‡Œå®šä¹‰ä¸‰å±‚\n",
    "        self.fc1 = nn.Linear(s_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, h_size*2)\n",
    "        self.fc3 = nn.Linear(h_size*2, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # åœ¨è¿™é‡Œå®šä¹‰å‰å‘ä¼ æ’­è¿‡ç¨‹\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action.item(), m.log_prob(action)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SM1QiGCSbBkM"
   },
   "source": [
    "### å®šä¹‰è¶…å‚æ•° âš™ï¸\n",
    "- å› ä¸ºè¿™ä¸ªç¯å¢ƒæ›´å¤æ‚ã€‚\n",
    "- æˆ‘ä»¬éœ€è¦æ›´å¤šçš„ç¥ç»å…ƒï¼Œç‰¹åˆ«æ˜¯å¯¹äºéšè—å±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y0uujOR_ypB6",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:35:01.421900Z",
     "start_time": "2025-08-12T12:35:01.417386Z"
    }
   },
   "source": [
    "pixelcopter_hyperparameters = {\n",
    "    \"h_size\": 64,\n",
    "    \"n_training_episodes\": 50000,\n",
    "    \"n_evaluation_episodes\": 10,\n",
    "    \"max_t\": 10000,\n",
    "    \"gamma\": 0.99,\n",
    "    \"lr\": 1e-4,\n",
    "    \"env_id\": env_id,\n",
    "    \"state_space\": s_size,\n",
    "    \"action_space\": a_size,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "### è®­ç»ƒå®ƒ\n",
    "- æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½è®­ç»ƒæˆ‘ä»¬çš„æ™ºèƒ½ä½“äº† ğŸ”¥ã€‚"
   ],
   "metadata": {
    "id": "wyvXTJWm9GJG"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7mM2P_ckysFE",
    "ExecuteTime": {
     "end_time": "2025-08-12T12:36:34.226633Z",
     "start_time": "2025-08-12T12:36:30.422160Z"
    }
   },
   "source": [
    "# åˆ›å»ºç­–ç•¥å¹¶å°†å…¶æ”¾ç½®åˆ°è®¾å¤‡ä¸Š\n",
    "# torch.manual_seed(50)\n",
    "pixelcopter_policy = PixelCopterPolicy(pixelcopter_hyperparameters[\"state_space\"],pixelcopter_hyperparameters[\"action_space\"], pixelcopter_hyperparameters[\"h_size\"]).to(device)\n",
    "pixelcopter_optimizer = optim.Adam(pixelcopter_policy.parameters(), lr=pixelcopter_hyperparameters[\"lr\"])"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v1HEqP-fy-Rf",
    "ExecuteTime": {
     "end_time": "2025-08-12T17:56:28.433628Z",
     "start_time": "2025-08-12T12:37:34.491350Z"
    }
   },
   "source": [
    "scores = reinforce(\n",
    "    pixelcopter_policy,\n",
    "    pixelcopter_optimizer,\n",
    "    pixelcopter_hyperparameters[\"n_training_episodes\"],\n",
    "    pixelcopter_hyperparameters[\"max_t\"],\n",
    "    pixelcopter_hyperparameters[\"gamma\"],\n",
    "    1000,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å›åˆ 1000\tå¹³å‡åˆ†æ•°: 4.45\n",
      "å›åˆ 2000\tå¹³å‡åˆ†æ•°: 6.49\n",
      "å›åˆ 3000\tå¹³å‡åˆ†æ•°: 9.65\n",
      "å›åˆ 4000\tå¹³å‡åˆ†æ•°: 9.38\n",
      "å›åˆ 5000\tå¹³å‡åˆ†æ•°: 10.92\n",
      "å›åˆ 6000\tå¹³å‡åˆ†æ•°: 13.16\n",
      "å›åˆ 7000\tå¹³å‡åˆ†æ•°: 16.60\n",
      "å›åˆ 8000\tå¹³å‡åˆ†æ•°: 20.44\n",
      "å›åˆ 9000\tå¹³å‡åˆ†æ•°: 21.16\n",
      "å›åˆ 10000\tå¹³å‡åˆ†æ•°: 21.29\n",
      "å›åˆ 11000\tå¹³å‡åˆ†æ•°: 23.74\n",
      "å›åˆ 12000\tå¹³å‡åˆ†æ•°: 25.15\n",
      "å›åˆ 13000\tå¹³å‡åˆ†æ•°: 20.83\n",
      "å›åˆ 14000\tå¹³å‡åˆ†æ•°: 26.05\n",
      "å›åˆ 15000\tå¹³å‡åˆ†æ•°: 21.60\n",
      "å›åˆ 16000\tå¹³å‡åˆ†æ•°: 30.59\n",
      "å›åˆ 17000\tå¹³å‡åˆ†æ•°: 27.95\n",
      "å›åˆ 18000\tå¹³å‡åˆ†æ•°: 27.53\n",
      "å›åˆ 19000\tå¹³å‡åˆ†æ•°: 31.01\n",
      "å›åˆ 20000\tå¹³å‡åˆ†æ•°: 24.79\n",
      "å›åˆ 21000\tå¹³å‡åˆ†æ•°: 33.51\n",
      "å›åˆ 22000\tå¹³å‡åˆ†æ•°: 34.43\n",
      "å›åˆ 23000\tå¹³å‡åˆ†æ•°: 29.17\n",
      "å›åˆ 24000\tå¹³å‡åˆ†æ•°: 33.71\n",
      "å›åˆ 25000\tå¹³å‡åˆ†æ•°: 37.35\n",
      "å›åˆ 26000\tå¹³å‡åˆ†æ•°: 29.06\n",
      "å›åˆ 27000\tå¹³å‡åˆ†æ•°: 21.70\n",
      "å›åˆ 28000\tå¹³å‡åˆ†æ•°: 25.08\n",
      "å›åˆ 29000\tå¹³å‡åˆ†æ•°: 29.40\n",
      "å›åˆ 30000\tå¹³å‡åˆ†æ•°: 36.96\n",
      "å›åˆ 31000\tå¹³å‡åˆ†æ•°: 43.21\n",
      "å›åˆ 32000\tå¹³å‡åˆ†æ•°: 30.58\n",
      "å›åˆ 33000\tå¹³å‡åˆ†æ•°: 43.62\n",
      "å›åˆ 34000\tå¹³å‡åˆ†æ•°: 46.33\n",
      "å›åˆ 35000\tå¹³å‡åˆ†æ•°: 53.47\n",
      "å›åˆ 36000\tå¹³å‡åˆ†æ•°: 37.60\n",
      "å›åˆ 37000\tå¹³å‡åˆ†æ•°: 23.46\n",
      "å›åˆ 38000\tå¹³å‡åˆ†æ•°: 52.37\n",
      "å›åˆ 39000\tå¹³å‡åˆ†æ•°: 54.17\n",
      "å›åˆ 40000\tå¹³å‡åˆ†æ•°: 44.95\n",
      "å›åˆ 41000\tå¹³å‡åˆ†æ•°: 53.32\n",
      "å›åˆ 42000\tå¹³å‡åˆ†æ•°: 46.35\n",
      "å›åˆ 43000\tå¹³å‡åˆ†æ•°: 37.40\n",
      "å›åˆ 44000\tå¹³å‡åˆ†æ•°: 56.35\n",
      "å›åˆ 45000\tå¹³å‡åˆ†æ•°: 58.51\n",
      "å›åˆ 46000\tå¹³å‡åˆ†æ•°: 49.61\n",
      "å›åˆ 47000\tå¹³å‡åˆ†æ•°: 66.16\n",
      "å›åˆ 48000\tå¹³å‡åˆ†æ•°: 67.40\n",
      "å›åˆ 49000\tå¹³å‡åˆ†æ•°: 52.13\n",
      "å›åˆ 50000\tå¹³å‡åˆ†æ•°: 55.52\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T18:41:39.600763Z",
     "start_time": "2025-08-12T18:41:39.592102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹åˆ°å½“å‰å·¥ä½œç›®å½•\n",
    "torch.save(pixelcopter_policy, \"pixelcopter_policy.pt\")\n"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "source": [
    "### åœ¨ Hub ä¸Šå‘å¸ƒæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹ ğŸ”¥"
   ],
   "metadata": {
    "id": "8kwFQ-Ip85BE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: å®šä¹‰ä½ çš„ repo_id {ä½ çš„ç”¨æˆ·å/Reinforce-Pixelcopter-v0}\n",
    "repo_id = \"a1024053774/Reinforce-Pixelcopter-v0\"\n",
    "push_to_hub(\n",
    "    repo_id,\n",
    "    pixelcopter_policy,  # The model we want to save\n",
    "    pixelcopter_hyperparameters,  # Hyperparameters\n",
    "    eval_env,  # Evaluation environment\n",
    "    video_fps=30\n",
    ")"
   ],
   "metadata": {
    "id": "6PtB7LRbTKWK",
    "ExecuteTime": {
     "end_time": "2025-08-12T18:38:52.054513Z",
     "start_time": "2025-08-12T18:38:51.554832Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x4 and 7x64)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[61]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# TODO: å®šä¹‰ä½ çš„ repo_id {ä½ çš„ç”¨æˆ·å/Reinforce-Pixelcopter-v0}\u001B[39;00m\n\u001B[32m      2\u001B[39m repo_id = \u001B[33m\"\u001B[39m\u001B[33ma1024053774/Reinforce-Pixelcopter-v0\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m push_to_hub(\n\u001B[32m      4\u001B[39m     repo_id,\n\u001B[32m      5\u001B[39m     pixelcopter_policy,  \u001B[38;5;66;03m# The model we want to save\u001B[39;00m\n\u001B[32m      6\u001B[39m     pixelcopter_hyperparameters,  \u001B[38;5;66;03m# Hyperparameters\u001B[39;00m\n\u001B[32m      7\u001B[39m     eval_env,  \u001B[38;5;66;03m# Evaluation environment\u001B[39;00m\n\u001B[32m      8\u001B[39m     video_fps=\u001B[32m30\u001B[39m\n\u001B[32m      9\u001B[39m )\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[55]\u001B[39m\u001B[32m, line 42\u001B[39m, in \u001B[36mpush_to_hub\u001B[39m\u001B[34m(repo_id, model, hyperparameters, eval_env, video_fps)\u001B[39m\n\u001B[32m     39\u001B[39m   json.dump(hyperparameters, outfile)\n\u001B[32m     41\u001B[39m \u001B[38;5;66;03m# æ­¥éª¤ 4: è¯„ä¼°æ¨¡å‹å¹¶æ„å»º JSON\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m mean_reward, std_reward = evaluate_agent(eval_env,\n\u001B[32m     43\u001B[39m                                         hyperparameters[\u001B[33m\"\u001B[39m\u001B[33mmax_t\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     44\u001B[39m                                         hyperparameters[\u001B[33m\"\u001B[39m\u001B[33mn_evaluation_episodes\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     45\u001B[39m                                         model)\n\u001B[32m     46\u001B[39m \u001B[38;5;66;03m# è·å–æ—¥æœŸæ—¶é—´\u001B[39;00m\n\u001B[32m     47\u001B[39m eval_datetime = datetime.datetime.now()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[59]\u001B[39m\u001B[32m, line 16\u001B[39m, in \u001B[36mevaluate_agent\u001B[39m\u001B[34m(env, max_steps, n_eval_episodes, policy)\u001B[39m\n\u001B[32m     13\u001B[39m total_rewards_ep = \u001B[32m0\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_steps):\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m   action, _ = policy.act(state)\n\u001B[32m     17\u001B[39m   new_state, reward, done, info = env.step(action)\n\u001B[32m     18\u001B[39m   total_rewards_ep += reward\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 21\u001B[39m, in \u001B[36mPixelCopterPolicy.act\u001B[39m\u001B[34m(self, state)\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mact\u001B[39m(\u001B[38;5;28mself\u001B[39m, state):\n\u001B[32m     20\u001B[39m     state = torch.from_numpy(state).float().unsqueeze(\u001B[32m0\u001B[39m).to(device)\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m     probs = \u001B[38;5;28mself\u001B[39m.forward(state).cpu()\n\u001B[32m     22\u001B[39m     m = Categorical(probs)\n\u001B[32m     23\u001B[39m     action = m.sample()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36mPixelCopterPolicy.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     13\u001B[39m     \u001B[38;5;66;03m# åœ¨è¿™é‡Œå®šä¹‰å‰å‘ä¼ æ’­è¿‡ç¨‹\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m     x = F.relu(\u001B[38;5;28mself\u001B[39m.fc1(x))\n\u001B[32m     15\u001B[39m     x = F.relu(\u001B[38;5;28mself\u001B[39m.fc2(x))\n\u001B[32m     16\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.fc3(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\DevelopmentSoftware\\Anaconda\\envs\\py311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\DevelopmentSoftware\\Anaconda\\envs\\py311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\DevelopmentSoftware\\Anaconda\\envs\\py311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.linear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m.weight, \u001B[38;5;28mself\u001B[39m.bias)\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (1x4 and 7x64)"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VDcJ29FcOyb"
   },
   "source": [
    "## ä¸€äº›é¢å¤–çš„æŒ‘æˆ˜ ğŸ†\n",
    "æœ€å¥½çš„å­¦ä¹ æ–¹å¼æ˜¯**äº²è‡ªåŠ¨æ‰‹å°è¯•**ï¼æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œå½“å‰çš„æ™ºèƒ½ä½“è¡¨ç°å¹¶ä¸å‡ºè‰²ã€‚ä½œä¸ºç¬¬ä¸€ä¸ªå»ºè®®ï¼Œä½ å¯ä»¥è®­ç»ƒæ›´å¤šçš„æ­¥æ•°ã€‚ä½†ä¹Ÿå¯ä»¥å°è¯•å¯»æ‰¾æ›´å¥½çš„å‚æ•°ã€‚\n",
    "\n",
    "åœ¨[æ’è¡Œæ¦œ](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard)ä¸Šï¼Œä½ ä¼šæ‰¾åˆ°ä½ çš„æ™ºèƒ½ä½“ã€‚ä½ èƒ½ç™»ä¸Šæ¦œé¦–å—ï¼Ÿ\n",
    "\n",
    "è¿™é‡Œæœ‰ä¸€äº›å®ç°è¿™ä¸€ç›®æ ‡çš„æ–¹æ³•ï¼š\n",
    "* è®­ç»ƒæ›´å¤šæ­¥æ•°\n",
    "* é€šè¿‡æŸ¥çœ‹ä½ åŒå­¦çš„åšæ³•æ¥å°è¯•ä¸åŒçš„è¶…å‚æ•° ğŸ‘‰ https://huggingface.co/models?other=reinforce\n",
    "* **å°†ä½ æ–°è®­ç»ƒçš„æ¨¡å‹æ¨é€åˆ° Hub** ğŸ”¥\n",
    "* **ä¸ºæ›´å¤æ‚çš„ç¯å¢ƒæ”¹è¿›å®ç°**ï¼ˆä¾‹å¦‚ï¼Œå°†ç½‘ç»œæ›´æ”¹ä¸ºå·ç§¯ç¥ç»ç½‘ç»œä»¥å¤„ç†\n",
    "ä½œä¸ºè§‚å¯Ÿçš„å¸§æ€ä¹ˆæ ·ï¼‰ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x62pP0PHdA-y"
   },
   "source": [
    "________________________________________________________________________\n",
    "\n",
    "**æ­å–œä½ å®Œæˆæœ¬å•å…ƒ**ï¼è¿™é‡Œæœ‰å¾ˆå¤šä¿¡æ¯ã€‚\n",
    "ä¹Ÿæ­å–œä½ å®Œæˆäº†æœ¬æ•™ç¨‹ã€‚ä½ åˆšåˆšä½¿ç”¨ PyTorch ä»å¤´å¼€å§‹ç¼–å†™äº†ä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œå¹¶å°†å…¶åˆ†äº«åˆ°äº† Hub ä¸Š ğŸ¥³ã€‚\n",
    "\n",
    "ä¸è¦çŠ¹è±«ï¼Œé€šè¿‡**ä¸ºæ›´å¤æ‚çš„ç¯å¢ƒæ”¹è¿›å®ç°æ¥è¿­ä»£æœ¬å•å…ƒ**ï¼ˆä¾‹å¦‚ï¼Œå°†ç½‘ç»œæ›´æ”¹ä¸ºå·ç§¯ç¥ç»ç½‘ç»œä»¥å¤„ç†ä½œä¸ºè§‚å¯Ÿçš„å¸§æ€ä¹ˆæ ·ï¼‰ï¼Ÿ\n",
    "\n",
    "åœ¨ä¸‹ä¸€ä¸ªå•å…ƒä¸­ï¼Œ**æˆ‘ä»¬å°†é€šè¿‡åœ¨ Unity ç¯å¢ƒä¸­è®­ç»ƒæ™ºèƒ½ä½“æ¥å­¦ä¹ æ›´å¤šå…³äº Unity MLAgents çš„çŸ¥è¯†**ã€‚è¿™æ ·ï¼Œä½ å°†å‡†å¤‡å¥½å‚åŠ  **AI vs AI æŒ‘æˆ˜èµ›ï¼Œåœ¨é‚£é‡Œä½ å°†è®­ç»ƒä½ çš„æ™ºèƒ½ä½“\n",
    "åœ¨é›ªçƒå¤§æˆ˜å’Œè¶³çƒæ¯”èµ›ä¸­ä¸å…¶ä»–æ™ºèƒ½ä½“ç«äº‰ã€‚**\n",
    "\n",
    "å¬èµ·æ¥å¾ˆæœ‰è¶£ï¼Ÿä¸‹æ¬¡è§ï¼\n",
    "\n",
    "æœ€åï¼Œæˆ‘ä»¬å¾ˆæƒ³**å¬å¬ä½ å¯¹è¯¾ç¨‹çš„çœ‹æ³•ä»¥åŠæˆ‘ä»¬å¦‚ä½•æ”¹è¿›å®ƒ**ã€‚å¦‚æœä½ æœ‰ä»»ä½•åé¦ˆï¼Œè¯· ğŸ‘‰  [å¡«å†™æ­¤è¡¨æ ¼](https://forms.gle/BzKXWzLAGZESGNaE9)\n",
    "\n",
    "æˆ‘ä»¬åœ¨ç¬¬ 5 å•å…ƒè§ï¼ğŸ”¥\n",
    "\n",
    "### ç»§ç»­å­¦ä¹ ï¼Œä¿æŒå‡ºè‰² ğŸ¤—\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
