{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D3NL_e4crQv"
   },
   "source": [
    "# 第 5 单元：ML-Agents 简介\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97ZiytXEgqIz"
   },
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/thumbnail.png\" alt=\"Thumbnail\"/>\n",
    "\n",
    "在这个 notebook 中，你将学习 ML-Agents 并训练两个智能体。\n",
    "\n",
    "- 第一个将学习**向生成的目标发射雪球**。\n",
    "- 第二个需要按下一个按钮来生成一个金字塔，然后导航到金字塔，将其推倒，**并移动到顶部的金砖**。为此，它需要探索其环境，我们将使用一种称为“好奇心”的技术。\n",
    "\n",
    "之后，你将能够**直接在浏览器中观看你的智能体玩游戏**。\n",
    "\n",
    "有关认证过程的更多信息，请查看此部分 👉 https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMYrDriDujzX"
   },
   "source": [
    "⬇️ 这是**你在本单元结束时将实现**的示例。⬇️\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBmFlh8suma-"
   },
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids.gif\" alt=\"Pyramids\"/>\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget.gif\" alt=\"SnowballTarget\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-cYE0K5iL-w"
   },
   "source": [
    "### 🎮 环境：\n",
    "\n",
    "- [金字塔 (Pyramids)](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#pyramids)\n",
    "- 雪球目标 (SnowballTarget)\n",
    "\n",
    "### 📚 RL-库：\n",
    "\n",
    "- [ML-Agents](https://github.com/Unity-Technologies/ml-agents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEhtaFh9i31S"
   },
   "source": [
    "我们一直在努力改进我们的教程，所以**如果你在这个 notebook 中发现任何问题**，请[在 GitHub 仓库中提出一个 issue](https://github.com/huggingface/deep-rl-class/issues)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7f63r3Yi5vE"
   },
   "source": [
    "## 这个 notebook 的目标 🏆\n",
    "\n",
    "在本 notebook 结束时，你将：\n",
    "\n",
    "- 了解环境库 **ML-Agents** 的工作原理。\n",
    "- 能够**在 Unity 环境中训练智能体**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viNzVbVaYvY3"
   },
   "source": [
    "## 这个 notebook 来自深度强化学习课程\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6p5HnEefISCB"
   },
   "source": [
    "在这门免费课程中，你将：\n",
    "\n",
    "- 📖 **理论与实践相结合**学习深度强化学习。\n",
    "- 🧑‍💻 学习**使用著名的深度强化学习库**，如 Stable Baselines3, RL Baselines3 Zoo, CleanRL 和 Sample Factory 2.0。\n",
    "- 🤖 在**独特的环境中训练智能体**\n",
    "\n",
    "更多内容请查看 📚 教学大纲 👉 https://huggingface.co/deep-rl-course/communication/publishing-schedule\n",
    "\n",
    "别忘了**<a href=\"http://eepurl.com/ic5ZUD\">注册课程</a>**（我们收集你的电子邮件是为了**在每个单元发布时向你发送链接，并为你提供有关挑战和更新的信息）。**\n",
    "\n",
    "\n",
    "保持联系的最佳方式是加入我们的 discord 服务器，与社区和我们交流 👉🏻 https://discord.gg/ydHrjt3WP5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-mo_6rXIjRi"
   },
   "source": [
    "## 先决条件 🏗️\n",
    "在深入学习这个 notebook 之前，你需要：\n",
    "\n",
    "🔲 📚 **通过阅读第 5 单元来学习 [什么是 ML-Agents 及其工作原理](https://huggingface.co/deep-rl-course/unit5/introduction)** 🤗  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYO1uD5Ujgdh"
   },
   "source": [
    "# 让我们开始训练我们的智能体吧 🚀\n",
    "\n",
    "**要为认证过程验证此实践，你只需将训练好的模型推送到 Hub**。这个没有要达到的结果来验证。但如果你想获得好的结果，你可以尝试达到：\n",
    "\n",
    "- 对于 `Pyramids`：平均奖励 = 1.75\n",
    "- 对于 `SnowballTarget`：平均奖励 = 15 或在一个回合中击中 30 个目标。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DssdIjk_8vZE"
   },
   "source": [
    "## 设置 GPU 💪\n",
    "- 为了**加速智能体的训练，我们将使用 GPU**。为此，请转到 `Runtime > Change Runtime type`\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTfCXHy68xBv"
   },
   "source": [
    "- `硬件加速器 > GPU`\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMH_aNJOLdj7"
   },
   "source": [
    "## 克隆仓库 🔽\n",
    "\n",
    "- 我们需要克隆包含 **ML-Agents** 的仓库。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TDvNXSYNLdj7",
    "ExecuteTime": {
     "end_time": "2025-08-17T13:31:59.714924Z",
     "start_time": "2025-08-17T13:31:36.073782Z"
    }
   },
   "source": [
    "%%capture\n",
    "# 克隆仓库（可能需要 3 分钟）\n",
    "!git clone --depth 1 https://github.com/Unity-Technologies/ml-agents"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fblYrfchLdj9"
   },
   "source": [
    "## 设置虚拟环境 🔽\n",
    "- 为了让 **ML-Agents** 在 Colab 中成功运行，Colab 的 Python 版本必须满足库的 Python 要求。\n",
    "\n",
    "- 我们可以在 `setup.py` 文件中的 `python_requires` 参数下检查支持的 Python 版本。这些文件是设置 **ML-Agents** 库所必需的，可以在以下位置找到：\n",
    "  - `/content/ml-agents/ml-agents/setup.py`\n",
    "  - `/content/ml-agents/ml-agents-envs/setup.py`\n",
    "\n",
    "- Colab 当前的 Python 版本（可以使用 `!python --version` 检查）与库的 `python_requires` 参数不匹配，因此安装可能会静默失败，并在稍后执行相同命令时导致如下错误：\n",
    "  - `/bin/bash: line 1: mlagents-learn: command not found`\n",
    "  - `/bin/bash: line 1: mlagents-push-to-hf: command not found`\n",
    "\n",
    "- 为了解决这个问题，我们将创建一个与 **ML-Agents** 库兼容的 Python 版本的虚拟环境。\n",
    "\n",
    "`注意：` *为了将来的兼容性，请务必检查安装文件中的 `python_requires` 参数，并在 Colab 的 Python 版本不兼容时，在下面的脚本中将你的虚拟环境设置为支持的最高 Python 版本*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx1TAhNqLdj9"
   },
   "outputs": [],
   "source": [
    "# Colab 当前的 Python 版本（与 ML-Agents 不兼容）\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8n69j15cLdj-"
   },
   "outputs": [],
   "source": [
    "# 安装 virtualenv 并创建一个虚拟环境\n",
    "!pip install virtualenv\n",
    "!virtualenv myenv\n",
    "\n",
    "# 下载 Miniconda 安装脚本\n",
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-py310_23.11.0-2-Linux-x86_64.sh\n",
    "# 添加执行权限\n",
    "!chmod +x Miniconda3-py310_23.11.0-2-Linux-x86_64.sh\n",
    "# 静默安装到 Colab 的标准目录\n",
    "!bash ./Miniconda3-py310_23.11.0-2-Linux-x86_64.sh -b -f -p /usr/local\n",
    "# 接受服务条款，防止后续命令出错\n",
    "!conda config --set auto_activate_base false\n",
    "!conda tos accept --override-channels --channel pkgs/main\n",
    "# 创建名为 mlagents 的新环境，并指定 Python 版本\n",
    "!conda create -n mlagents python=3.10.12 -y\n",
    "\n",
    "# 验证一下新环境中的 Python 版本，确保无误\n",
    "!/usr/local/envs/mlagents/bin/python --version\n",
    "# 预期的输出应该是： Python 3.10.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SQ4Ps4gLdj-"
   },
   "outputs": [],
   "source": [
    "# 新虚拟环境中的 Python 版本（与 ML-Agents 兼容）\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nl5OwdwNLdj_"
   },
   "source": [
    "## 安装依赖项 🔽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cLaIlNQLdj_"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# 激活我们刚刚创建的 conda 环境\n",
    "source /usr/local/bin/activate mlagents\n",
    "\n",
    "# 进入 ml-agents 仓库目录\n",
    "cd ml-agents\n",
    "\n",
    "echo \"--- 正在安装 ml-agents-envs ---\"\n",
    "pip install -e ./ml-agents-envs\n",
    "\n",
    "echo \"--- 正在安装 ml-agents ---\"\n",
    "pip install -e ./ml-agents\n",
    "\n",
    "echo \"--- 依赖安装完成 ---\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5_7Ptd_kEcG"
   },
   "source": [
    "## 雪球目标 (SnowballTarget) ⛄\n",
    "\n",
    "如果你需要复习这个环境的工作原理，请查看此部分 👉\n",
    "https://huggingface.co/deep-rl-course/unit5/snowball-target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRY5ufKUKfhI"
   },
   "source": [
    "### 下载环境 zip 文件并将其移动到 `./training-envs-executables/linux/`\n",
    "- 我们的环境可执行文件在一个 zip 文件中。\n",
    "- 我们需要下载它并将其放置到 `./training-envs-executables/linux/`\n",
    "- 我们使用 linux 可执行文件，因为我们使用 colab，而 colab 机器的操作系统是 Ubuntu (linux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9Ls6_6eOKiA"
   },
   "outputs": [],
   "source": [
    "# 这里，我们创建 training-envs-executables 和 linux 目录\n",
    "!mkdir ./training-envs-executables\n",
    "!mkdir ./training-envs-executables/linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekSh8LWawkB5"
   },
   "source": [
    "我们使用 `wget` 从 https://github.com/huggingface/Snowball-Target 下载了 SnowballTarget.zip 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LosWO50wa77"
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/huggingface/Snowball-Target/raw/main/SnowballTarget.zip\" -O ./training-envs-executables/linux/SnowballTarget.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LLVaEEK3ayi"
   },
   "source": [
    "我们解压 executable.zip 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FPx0an9IAwO"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SnowballTarget.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyumV5XfPKzu"
   },
   "source": [
    "确保你的文件是可访问的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdFsLJ11JvQf"
   },
   "outputs": [],
   "source": [
    "!chmod -R 755 ./training-envs-executables/linux/SnowballTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAuEq32Mwvtz"
   },
   "source": [
    "### 定义 SnowballTarget 配置文件\n",
    "- 在 ML-Agents 中，你需要在 `config.yaml` 文件中定义**训练超参数**。\n",
    "\n",
    "有很多超参数。为了更好地了解它们，你应该查阅[文档](https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md)中对每一个的解释。\n",
    "\n",
    "\n",
    "所以你需要在 `./content/ml-agents/config/ppo/` 中创建一个 `SnowballTarget.yaml` 配置文件。\n",
    "\n",
    "我们会在这里给你这个配置的第一个版本（复制并粘贴到你的 `SnowballTarget.yaml` 文件中），**但你应该修改它**。\n",
    "\n",
    "```\n",
    "behaviors:\n",
    "  SnowballTarget:\n",
    "    trainer_type: ppo\n",
    "    summary_freq: 10000\n",
    "    keep_checkpoints: 10\n",
    "    checkpoint_interval: 50000\n",
    "    max_steps: 200000\n",
    "    time_horizon: 64\n",
    "    threaded: false\n",
    "    hyperparameters:\n",
    "      learning_rate: 0.0003\n",
    "      learning_rate_schedule: linear\n",
    "      batch_size: 128\n",
    "      buffer_size: 2048\n",
    "      beta: 0.005\n",
    "      epsilon: 0.2\n",
    "      lambd: 0.95\n",
    "      num_epoch: 3\n",
    "    network_settings:\n",
    "      normalize: false\n",
    "      hidden_units: 256\n",
    "      num_layers: 2\n",
    "      vis_encode_type: simple\n",
    "    reward_signals:\n",
    "      extrinsic:\n",
    "        gamma: 0.99\n",
    "        strength: 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4U3sRH4N4h_l"
   },
   "source": [
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config1.png\" alt=\"Config SnowballTarget\"/>\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballfight_config2.png\" alt=\"Config SnowballTarget\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJJdo_5AyoGo"
   },
   "source": [
    "作为实验，你还应该尝试修改一些其他的超参数。Unity 提供了非常[好的文档，在这里解释了每一个超参数](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md)。\n",
    "\n",
    "现在你已经创建了配置文件并了解了大多数超参数的作用，我们准备好训练我们的智能体了 🔥。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9fI555bO12v"
   },
   "source": [
    "### 训练智能体\n",
    "\n",
    "要训练我们的智能体，我们只需要**启动 mlagents-learn 并选择包含环境的可执行文件**。\n",
    "\n",
    "我们定义了四个参数：\n",
    "\n",
    "1. `mlagents-learn <config>`：超参数配置文件的路径。\n",
    "2. `--env`：环境可执行文件的位置。\n",
    "3. `--run_id`：你想要为你的训练运行指定的名称。\n",
    "4. `--no-graphics`：在训练期间不启动可视化。\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentslearn.png\" alt=\"MlAgents learn\"/>\n",
    "\n",
    "训练模型并使用 `--resume` 标志在中断的情况下继续训练。\n",
    "\n",
    "> 如果以及当你使用 `--resume` 时第一次失败，请尝试再次运行该代码块以绕过错误。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lN32oWF8zPjs"
   },
   "source": [
    "根据你的配置，训练将花费 10 到 35 分钟，去喝杯 ☕️ 吧，你值得拥有 🤗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS-Yh1UdHfzy"
   },
   "outputs": [],
   "source": [
    "!mlagents-learn ./config/ppo/SnowballTarget.yaml --env=./training-envs-executables/linux/SnowballTarget/SnowballTarget --run-id=\"SnowballTarget1\" --no-graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Vue94AzPy1t"
   },
   "source": [
    "### 将智能体推送到 🤗 Hub\n",
    "\n",
    "- 现在我们已经训练了我们的智能体，我们**准备好将它推送到 Hub，以便能够在你的浏览器上可视化它的游戏过程🔥。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izT6FpgNzZ6R"
   },
   "source": [
    "为了能够与社区分享你的模型，还需要遵循三个步骤：\n",
    "\n",
    "1️⃣（如果还没有）创建一个 HF 账户 ➡ https://huggingface.co/join\n",
    "\n",
    "2️⃣ 登录，然后你需要从 Hugging Face 网站存储你的身份验证令牌。\n",
    "- 创建一个新令牌（https://huggingface.co/settings/tokens）**并赋予 write 角色**\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">\n",
    "\n",
    "- 复制令牌\n",
    "- 运行下面的单元格并粘贴令牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKt2vsYoK56o"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSU9qD9_6dem"
   },
   "source": [
    "如果你不想使用 Google Colab 或 Jupyter Notebook，你需要改用这个命令：`huggingface-cli login`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KK4fPfnczunT"
   },
   "source": [
    "然后，我们只需要运行 `mlagents-push-to-hf`。\n",
    "\n",
    "我们定义了 4 个参数：\n",
    "\n",
    "1. `--run-id`：训练运行的 ID 名称。\n",
    "2. `--local-dir`：智能体的保存位置，即 `results/<run_id name>`，所以在我的例子中是 `results/First Training`。\n",
    "3. `--repo-id`：你想要创建或更新的 Hugging Face 仓库的名称。格式总是 `<你的 huggingface 用户名>/<仓库名>`\n",
    "如果仓库不存在，**它将被自动创建**\n",
    "4. `--commit-message`：因为 HF 仓库是 git 仓库，所以你需要定义一个提交信息。\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/mlagentspushtohub.png\" alt=\"Push to Hub\"/>\n",
    "\n",
    "例如：\n",
    "\n",
    "`!mlagents-push-to-hf  --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"ThomasSimonini/ppo-SnowballTarget\"  --commit-message=\"First Push\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAFzVB7OYj_H"
   },
   "outputs": [],
   "source": [
    "!mlagents-push-to-hf --run-id=\"SnowballTarget1\" --local-dir=\"./results/SnowballTarget1\" --repo-id=\"ThomasSimonini/ppo-SnowballTarget\" --commit-message=\"First Push\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGEFAIboLVc6"
   },
   "outputs": [],
   "source": [
    "!mlagents-push-to-hf  --run-id= # 添加你的运行 ID  --local-dir= # 你的本地目录  --repo-id= # 你的仓库 ID  --commit-message= # 你的提交信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yborB0850FTM"
   },
   "source": [
    "另外，如果一切顺利，你应该在过程结束时看到这个（但 URL 不同 😆）：\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Your model is pushed to the hub. You can view your model here: [https://huggingface.co/ThomasSimonini/ppo-SnowballTarget](https://huggingface.co/ThomasSimonini/ppo-SnowballTarget)\n",
    "```\n",
    "\n",
    "这是你模型的链接，它包含一个模型卡片，解释了如何使用它，你的 Tensorboard 和你的配置文件。**最棒的是它是一个 git 仓库，这意味着你可以有不同的提交，用新的推送更新你的仓库等等。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Uaon2cg0NrL"
   },
   "source": [
    "但现在最精彩的部分来了：**能够在线观看你的智能体 👀。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMc4oOsE0QiZ"
   },
   "source": [
    "### 观看你的智能体玩游戏 👀\n",
    "\n",
    "这一步很简单：\n",
    "\n",
    "1. 前往这里：https://huggingface.co/spaces/ThomasSimonini/ML-Agents-SnowballTarget\n",
    "\n",
    "2. 启动游戏并通过点击右下角按钮将其全屏\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget_load.png\" alt=\"Snowballtarget load\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djs8c5rR0Z8a"
   },
   "source": [
    "1. 在步骤 1 中，输入你的用户名（你的用户名区分大小写：例如，我的用户名是 ThomasSimonini，而不是 thomassimonini 或 ThOmasImoNInI）并点击搜索按钮。\n",
    "\n",
    "2. 在步骤 2 中，选择你的模型仓库。\n",
    "\n",
    "3. 在步骤 3 中，**选择你想要重放的模型**：\n",
    "  - 我有多个模型，因为我们每 500000 个时间步保存一个模型。\n",
    "  - 但因为我想要最新的，我选择 `SnowballTarget.onnx`\n",
    "\n",
    "👉 一个不错的做法是**尝试用不同步骤的模型来观察智能体的进步。**\n",
    "\n",
    "不要犹豫，在 discord 的 #rl-i-made-this 频道分享你的智能体获得的最高分 🔥\n",
    "\n",
    "现在让我们尝试一个更难的环境，叫做 Pyramids...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVMwRi4y_tmx"
   },
   "source": [
    "## 金字塔 (Pyramids) 🏆\n",
    "\n",
    "### 下载环境 zip 文件并将其移动到 `./training-envs-executables/linux/`\n",
    "- 我们的环境可执行文件在一个 zip 文件中。\n",
    "- 我们需要下载它并将其放置到 `./training-envs-executables/linux/`\n",
    "- 我们使用 linux 可执行文件，因为我们使用 colab，而 colab 机器的操作系统是 Ubuntu (linux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2C48SGZjZYw"
   },
   "source": [
    "我们使用 `wget` 从 https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip 下载了 Pyramids.zip 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWh8Pl3sjZY2"
   },
   "outputs": [],
   "source": [
    "!wget \"https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip\" -O ./training-envs-executables/linux/Pyramids.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5LXPOPujZY3"
   },
   "source": [
    "我们解压 executable.zip 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmNgFdXhjZY3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/Pyramids.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1jxwhrJjZY3"
   },
   "source": [
    "确保你的文件是可访问的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fDd03btjZY3"
   },
   "outputs": [],
   "source": [
    "!chmod -R 755 ./training-envs-executables/linux/Pyramids/Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqceIATXAgih"
   },
   "source": [
    "### 修改 PyramidsRND 配置文件\n",
    "- 与第一个自定义环境不同，**Pyramids 是由 Unity 团队制作的**。\n",
    "- 所以 PyramidsRND 配置文件已经存在，位于 `./content/ml-agents/config/ppo/PyramidsRND.yaml`\n",
    "- 你可能会问为什么 PyramidsRND 中有 “RND”。RND 代表*随机网络蒸馏*，这是一种产生好奇心奖励的方法。如果你想了解更多关于这项技术的信息，我们写了一篇文章来解释它：https://medium.com/data-from-the-trenches/curiosity-driven-learning-through-random-network-distillation-488ffd8e5938\n",
    "\n",
    "对于这次训练，我们将修改一件事：\n",
    "- 总训练步数超参数太高了，因为我们仅用 100 万个训练步数就可以达到基准（平均奖励 = 1.75）。\n",
    "👉 为此，我们进入 `config/ppo/PyramidsRND.yaml`，**并将 `max_steps` 修改为 `1000000`。**\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids-config.png\" alt=\"Pyramids config\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI-5aPL7BWVk"
   },
   "source": [
    "作为实验，你还应该尝试修改一些其他的超参数，Unity 在[这里提供了非常好的文档来解释它们中的每一个](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Training-Configuration-File.md)。\n",
    "\n",
    "我们现在准备好训练我们的智能体了 🔥。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5hr1rvIBdZH"
   },
   "source": [
    "### 训练智能体\n",
    "\n",
    "根据你的机器，训练将花费 30 到 45 分钟，去喝杯 ☕️ 吧，你值得拥有 🤗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXi4-IaHBhqD"
   },
   "outputs": [],
   "source": [
    "!mlagents-learn ./config/ppo/PyramidsRND.yaml --env=./training-envs-executables/linux/Pyramids/Pyramids --run-id=\"Pyramids Training\" --no-graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txonKxuSByut"
   },
   "source": [
    "### 将智能体推送到 🤗 Hub\n",
    "\n",
    "- 现在我们已经训练了我们的智能体，我们**准备好将它推送到 Hub，以便能够在你的浏览器上可视化它的游戏过程🔥。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiEQbv7rB4mU"
   },
   "outputs": [],
   "source": [
    "!mlagents-push-to-hf  --run-id= # 添加你的运行 ID  --local-dir= # 你的本地目录  --repo-id= # 你的仓库 ID  --commit-message= # 你的提交信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aZfgxo-CDeQ"
   },
   "source": [
    "### 观看你的智能体玩游戏 👀\n",
    "\n",
    "👉 https://huggingface.co/spaces/unity/ML-Agents-Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGG_oq2n0wjB"
   },
   "source": [
    "### 🎁 奖励：为什么不试试在另一个环境中训练呢？\n",
    "现在你已经知道如何使用 MLAgents 训练智能体了，**为什么不试试另一个环境呢？**\n",
    "\n",
    "MLAgents 提供了 17 种不同的环境，我们也在构建一些自定义的环境。学习的最佳方式是亲自动手尝试，祝你玩得开心。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSAkJxSr0z6-"
   },
   "source": [
    "![cover](https://miro.medium.com/max/1400/0*xERdThTRRM2k_U9f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiyF4FX-04JB"
   },
   "source": [
    "你可以在这里找到 Unity 官方环境的完整列表 👉 https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md\n",
    "\n",
    "用于可视化你的智能体的演示 👉 https://huggingface.co/unity\n",
    "\n",
    "目前我们集成了：\n",
    "- [Worm](https://huggingface.co/spaces/unity/ML-Agents-Worm) 演示，你在其中教**一条虫子爬行**。\n",
    "- [Walker](https://huggingface.co/spaces/unity/ML-Agents-Walker) 演示，你在其中教一个智能体**走向一个目标**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI6dPWmh064H"
   },
   "source": [
    "今天就到这里。恭喜你完成了本教程！\n",
    "\n",
    "学习的最佳方式是实践和尝试。为什么不试试另一个环境呢？ML-Agents 有 17 种不同的环境，但你也可以创建自己的环境？查看文档，玩得开心！\n",
    "\n",
    "我们第 6 单元再见 🔥，\n",
    "\n",
    "## 持续学习，保持出色 🤗"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
